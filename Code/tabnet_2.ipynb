{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Tabnet_Raw_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace((np.inf, -np.inf), np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.4327  | val_0_auc: 0.58151 |  0:00:30s\n",
      "epoch 1  | loss: 0.25713 | val_0_auc: 0.54818 |  0:00:31s\n",
      "epoch 2  | loss: 0.24835 | val_0_auc: 0.54512 |  0:00:33s\n",
      "epoch 3  | loss: 0.19785 | val_0_auc: 0.55456 |  0:00:34s\n",
      "epoch 4  | loss: 0.18815 | val_0_auc: 0.62922 |  0:00:35s\n",
      "epoch 5  | loss: 0.17074 | val_0_auc: 0.70187 |  0:00:37s\n",
      "epoch 6  | loss: 0.15904 | val_0_auc: 0.72469 |  0:00:38s\n",
      "epoch 7  | loss: 0.15643 | val_0_auc: 0.74569 |  0:00:40s\n",
      "epoch 8  | loss: 0.16361 | val_0_auc: 0.73602 |  0:00:41s\n",
      "epoch 9  | loss: 0.15598 | val_0_auc: 0.79541 |  0:00:43s\n",
      "epoch 10 | loss: 0.14196 | val_0_auc: 0.77802 |  0:00:44s\n",
      "epoch 11 | loss: 0.14099 | val_0_auc: 0.78336 |  0:00:45s\n",
      "epoch 12 | loss: 0.14081 | val_0_auc: 0.79199 |  0:00:47s\n",
      "epoch 13 | loss: 0.13793 | val_0_auc: 0.81193 |  0:00:48s\n",
      "epoch 14 | loss: 0.1429  | val_0_auc: 0.78983 |  0:00:49s\n",
      "epoch 15 | loss: 0.13843 | val_0_auc: 0.7886  |  0:00:50s\n",
      "epoch 16 | loss: 0.13454 | val_0_auc: 0.79515 |  0:00:50s\n",
      "epoch 17 | loss: 0.13558 | val_0_auc: 0.80877 |  0:00:51s\n",
      "epoch 18 | loss: 0.13334 | val_0_auc: 0.80245 |  0:00:52s\n",
      "epoch 19 | loss: 0.13689 | val_0_auc: 0.79657 |  0:00:53s\n",
      "epoch 20 | loss: 0.13914 | val_0_auc: 0.81682 |  0:00:54s\n",
      "epoch 21 | loss: 0.13194 | val_0_auc: 0.82171 |  0:00:55s\n",
      "epoch 22 | loss: 0.13547 | val_0_auc: 0.81831 |  0:00:56s\n",
      "epoch 23 | loss: 0.13255 | val_0_auc: 0.80514 |  0:00:57s\n",
      "epoch 24 | loss: 0.13892 | val_0_auc: 0.83021 |  0:00:58s\n",
      "epoch 25 | loss: 0.13746 | val_0_auc: 0.83592 |  0:00:59s\n",
      "epoch 26 | loss: 0.13476 | val_0_auc: 0.84141 |  0:01:00s\n",
      "epoch 27 | loss: 0.13838 | val_0_auc: 0.82734 |  0:01:01s\n",
      "epoch 28 | loss: 0.13781 | val_0_auc: 0.8276  |  0:01:02s\n",
      "epoch 29 | loss: 0.14258 | val_0_auc: 0.82467 |  0:01:03s\n",
      "epoch 30 | loss: 0.1357  | val_0_auc: 0.7968  |  0:01:03s\n",
      "epoch 31 | loss: 0.13823 | val_0_auc: 0.76169 |  0:01:05s\n",
      "epoch 32 | loss: 0.13752 | val_0_auc: 0.77923 |  0:01:06s\n",
      "epoch 33 | loss: 0.13121 | val_0_auc: 0.76304 |  0:01:06s\n",
      "epoch 34 | loss: 0.13935 | val_0_auc: 0.77857 |  0:01:07s\n",
      "epoch 35 | loss: 0.13319 | val_0_auc: 0.83541 |  0:01:08s\n",
      "epoch 36 | loss: 0.13374 | val_0_auc: 0.839   |  0:01:08s\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.84141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[4790    6]\n",
      " [ 180    6]]\n",
      "Accuracy: 0.962665596146126\n",
      "Precision: 0.5\n",
      "Recall: 0.03225806451612903\n",
      "F1-score: 0.06060606060606061\n",
      "{'자기자본구성비율': 0.0008080892251332609, '설비투자효율': 0.0009330250660546965, '총자본투자효율': 2.5077186086357095e-05, '이자보상배율(이자비용)': 0.022491964482881002, '유동비율': 0.04098272510919903, '당좌비율': 0.007880806493676258, '부채비율': 0.026749017217086345, '총자본정상영업이익률': 8.531247133723453e-05, '매출액정상영업이익률': 0.016002351825675856, '매출액순이익률': 0.03216719070502078, '자기자본순이익률': 0.06195354965929166, '매출채권회전률': 0.02636616853374424, '재고자산회전률': 0.04973132360652812, '총자본회전률': 0.007630245779718587, '순운전자본비율': 0.16475490304719126, '매출액증가율': 0.07488827141956922, '총자본증가율': 0.033282353164258226, '유동자산증가율': 0.0002729360645514547, '유형자산증가율': 0.007710189925954246, '영업이익증가율': 0.026741313489286128, '순이익증가율': 0.017781308132499268, 'RETA': 0.061667804783938754, 'EBTA': 0.00017181801990063711, 'OM': 0.0009783749939243588, '종업원수증가율': 0.00018323762580364767, '영업이익변화율': 4.761290636460907e-05, '매출액변화율': 0.01946314273393609, '당기순이익변화율': 0.006075360461332463, 'DOL': 0.0007730747107721431, 'DFL': 3.0558955266309395e-05, 'EV/EBITDA': 6.564961366295386e-05, '영업활동으로 인한 현금흐름': 0.0008633481081809233, '금융비용부담률': 0.010389456027118596, '고정비율': 0.04109699251814306, 'R&D비율': 0.00021263837486895995, '채무부담비율': 0.010960790096601116, '거래량회전율': 4.068991745829323e-05, '로그시가총액': 0.22443086609994478, '수정거래량': 1.0320837888136104e-05, '거래량증가율': 5.361221766167754e-07, '시가총액증가율': 0.0005637045825769375, '시가총액': 0.0027358999053975126}\n"
     ]
    }
   ],
   "source": [
    "# With 'train_test split by years' data\n",
    "\n",
    "train = df[df['회계년도'] <= 2015]\n",
    "test = df[df['회계년도'] > 2015]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.40034 | val_0_auc: 0.46156 |  0:00:00s\n",
      "epoch 1  | loss: 0.21533 | val_0_auc: 0.50309 |  0:00:01s\n",
      "epoch 2  | loss: 0.19749 | val_0_auc: 0.62057 |  0:00:02s\n",
      "epoch 3  | loss: 0.17417 | val_0_auc: 0.55469 |  0:00:02s\n",
      "epoch 4  | loss: 0.15966 | val_0_auc: 0.71219 |  0:00:03s\n",
      "epoch 5  | loss: 0.15208 | val_0_auc: 0.763   |  0:00:04s\n",
      "epoch 6  | loss: 0.15089 | val_0_auc: 0.76233 |  0:00:04s\n",
      "epoch 7  | loss: 0.14718 | val_0_auc: 0.79313 |  0:00:05s\n",
      "epoch 8  | loss: 0.14119 | val_0_auc: 0.77597 |  0:00:05s\n",
      "epoch 9  | loss: 0.13731 | val_0_auc: 0.78541 |  0:00:06s\n",
      "epoch 10 | loss: 0.13361 | val_0_auc: 0.78602 |  0:00:07s\n",
      "epoch 11 | loss: 0.12759 | val_0_auc: 0.81955 |  0:00:07s\n",
      "epoch 12 | loss: 0.14331 | val_0_auc: 0.83164 |  0:00:08s\n",
      "epoch 13 | loss: 0.13703 | val_0_auc: 0.8333  |  0:00:09s\n",
      "epoch 14 | loss: 0.13534 | val_0_auc: 0.8299  |  0:00:09s\n",
      "epoch 15 | loss: 0.12712 | val_0_auc: 0.8491  |  0:00:10s\n",
      "epoch 16 | loss: 0.13394 | val_0_auc: 0.8585  |  0:00:11s\n",
      "epoch 17 | loss: 0.13452 | val_0_auc: 0.85635 |  0:00:11s\n",
      "epoch 18 | loss: 0.13332 | val_0_auc: 0.84844 |  0:00:12s\n",
      "epoch 19 | loss: 0.13305 | val_0_auc: 0.84149 |  0:00:13s\n",
      "epoch 20 | loss: 0.12312 | val_0_auc: 0.843   |  0:00:13s\n",
      "epoch 21 | loss: 0.12832 | val_0_auc: 0.84384 |  0:00:14s\n",
      "epoch 22 | loss: 0.13115 | val_0_auc: 0.85162 |  0:00:15s\n",
      "epoch 23 | loss: 0.12909 | val_0_auc: 0.85567 |  0:00:15s\n",
      "epoch 24 | loss: 0.13121 | val_0_auc: 0.8562  |  0:00:16s\n",
      "epoch 25 | loss: 0.12698 | val_0_auc: 0.85098 |  0:00:16s\n",
      "epoch 26 | loss: 0.13192 | val_0_auc: 0.8469  |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.8585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1947    2]\n",
      " [  76    3]]\n",
      "Accuracy: 0.9615384615384616\n",
      "Precision: 0.6\n",
      "Recall: 0.0379746835443038\n",
      "F1-score: 0.07142857142857144\n",
      "{'자기자본구성비율': 0.002841075290054547, '설비투자효율': 0.0008899565943526075, '총자본투자효율': 7.012592897536443e-05, '이자보상배율(이자비용)': 0.00032876851497568753, '유동비율': 0.00045656213794516347, '당좌비율': 0.0005359530255079969, '부채비율': 0.012427779512210597, '총자본정상영업이익률': 0.00303521941239578, '매출액정상영업이익률': 0.0008637038078991044, '매출액순이익률': 0.027494607368683487, '자기자본순이익률': 0.28884986771706755, '매출채권회전률': 0.18611284620334587, '재고자산회전률': 0.0009445219893499821, '총자본회전률': 0.005078601912416747, '순운전자본비율': 0.0006180638790743157, '매출액증가율': 0.0, '총자본증가율': 0.10704979422341988, '유동자산증가율': 6.67223745636649e-08, '유형자산증가율': 0.00041207122036000197, '영업이익증가율': 0.0005887820453415095, '순이익증가율': 5.082344811099751e-05, 'RETA': 0.008861586106631725, 'EBTA': 0.15839268488559274, 'OM': 0.0008579370415106809, '종업원수증가율': 0.012374921760111603, '영업이익변화율': 0.0014409445636766225, '매출액변화율': 0.006856792065534876, '당기순이익변화율': 8.978308350122175e-06, 'DOL': 0.00015977259707924935, 'DFL': 0.04172429631628268, 'EV/EBITDA': 0.003054555600617056, '영업활동으로 인한 현금흐름': 0.001826381941726491, '금융비용부담률': 0.04805842330093059, '고정비율': 0.02151993722642299, 'R&D비율': 0.010584649419769927, '채무부담비율': 0.014259120549139791, '거래량회전율': 0.0015741230728611147, '로그시가총액': 0.0003124949956301699, '수정거래량': 0.023464042150563236, '거래량증가율': 0.005817924714932393, '시가총액증가율': 0.0, '시가총액': 0.00020124242877417832}\n"
     ]
    }
   ],
   "source": [
    "# No hyperparameter tuning with raw data splitted by train_test_split method\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#scaler.fit(X_test)\n",
    "#X_train = scaler.transform(X_train) \n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classes=[0, 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64017 | val_0_auc: 0.71455 |  0:00:01s\n",
      "epoch 1  | loss: 0.38516 | val_0_auc: 0.80538 |  0:00:02s\n",
      "epoch 2  | loss: 0.32628 | val_0_auc: 0.84263 |  0:00:03s\n",
      "epoch 3  | loss: 0.29912 | val_0_auc: 0.85046 |  0:00:04s\n",
      "epoch 4  | loss: 0.29477 | val_0_auc: 0.87588 |  0:00:05s\n",
      "epoch 5  | loss: 0.28715 | val_0_auc: 0.8972  |  0:00:06s\n",
      "epoch 6  | loss: 0.28614 | val_0_auc: 0.90747 |  0:00:07s\n",
      "epoch 7  | loss: 0.28025 | val_0_auc: 0.90969 |  0:00:08s\n",
      "epoch 8  | loss: 0.27768 | val_0_auc: 0.90804 |  0:00:09s\n",
      "epoch 9  | loss: 0.26938 | val_0_auc: 0.90734 |  0:00:09s\n",
      "epoch 10 | loss: 0.26534 | val_0_auc: 0.91248 |  0:00:10s\n",
      "epoch 11 | loss: 0.26252 | val_0_auc: 0.92167 |  0:00:11s\n",
      "epoch 12 | loss: 0.25678 | val_0_auc: 0.92085 |  0:00:12s\n",
      "epoch 13 | loss: 0.25119 | val_0_auc: 0.92318 |  0:00:13s\n",
      "epoch 14 | loss: 0.24817 | val_0_auc: 0.92896 |  0:00:14s\n",
      "epoch 15 | loss: 0.23957 | val_0_auc: 0.93201 |  0:00:15s\n",
      "epoch 16 | loss: 0.23755 | val_0_auc: 0.93208 |  0:00:16s\n",
      "epoch 17 | loss: 0.23636 | val_0_auc: 0.93604 |  0:00:17s\n",
      "epoch 18 | loss: 0.23807 | val_0_auc: 0.93791 |  0:00:18s\n",
      "epoch 19 | loss: 0.23046 | val_0_auc: 0.93552 |  0:00:19s\n",
      "epoch 20 | loss: 0.2279  | val_0_auc: 0.93765 |  0:00:20s\n",
      "epoch 21 | loss: 0.22199 | val_0_auc: 0.93865 |  0:00:21s\n",
      "epoch 22 | loss: 0.22057 | val_0_auc: 0.93754 |  0:00:22s\n",
      "epoch 23 | loss: 0.21391 | val_0_auc: 0.9385  |  0:00:23s\n",
      "epoch 24 | loss: 0.22094 | val_0_auc: 0.94393 |  0:00:24s\n",
      "epoch 25 | loss: 0.20996 | val_0_auc: 0.94542 |  0:00:25s\n",
      "epoch 26 | loss: 0.21239 | val_0_auc: 0.94582 |  0:00:26s\n",
      "epoch 27 | loss: 0.20736 | val_0_auc: 0.94666 |  0:00:27s\n",
      "epoch 28 | loss: 0.20772 | val_0_auc: 0.94493 |  0:00:28s\n",
      "epoch 29 | loss: 0.20891 | val_0_auc: 0.94766 |  0:00:29s\n",
      "epoch 30 | loss: 0.20517 | val_0_auc: 0.94679 |  0:00:30s\n",
      "epoch 31 | loss: 0.21025 | val_0_auc: 0.94545 |  0:00:31s\n",
      "epoch 32 | loss: 0.20642 | val_0_auc: 0.94729 |  0:00:32s\n",
      "epoch 33 | loss: 0.19849 | val_0_auc: 0.94917 |  0:00:33s\n",
      "epoch 34 | loss: 0.20215 | val_0_auc: 0.95006 |  0:00:33s\n",
      "epoch 35 | loss: 0.20851 | val_0_auc: 0.94677 |  0:00:35s\n",
      "epoch 36 | loss: 0.20084 | val_0_auc: 0.95073 |  0:00:36s\n",
      "epoch 37 | loss: 0.19926 | val_0_auc: 0.95227 |  0:00:37s\n",
      "epoch 38 | loss: 0.19483 | val_0_auc: 0.95102 |  0:00:38s\n",
      "epoch 39 | loss: 0.1951  | val_0_auc: 0.95091 |  0:00:39s\n",
      "epoch 40 | loss: 0.18694 | val_0_auc: 0.95292 |  0:00:40s\n",
      "epoch 41 | loss: 0.18728 | val_0_auc: 0.95401 |  0:00:40s\n",
      "epoch 42 | loss: 0.18914 | val_0_auc: 0.95568 |  0:00:41s\n",
      "epoch 43 | loss: 0.18498 | val_0_auc: 0.95431 |  0:00:42s\n",
      "epoch 44 | loss: 0.18154 | val_0_auc: 0.9546  |  0:00:43s\n",
      "epoch 45 | loss: 0.1762  | val_0_auc: 0.95592 |  0:00:44s\n",
      "epoch 46 | loss: 0.18271 | val_0_auc: 0.95561 |  0:00:45s\n",
      "epoch 47 | loss: 0.18067 | val_0_auc: 0.95884 |  0:00:46s\n",
      "epoch 48 | loss: 0.17896 | val_0_auc: 0.95754 |  0:00:47s\n",
      "epoch 49 | loss: 0.17754 | val_0_auc: 0.95246 |  0:00:48s\n",
      "epoch 50 | loss: 0.17033 | val_0_auc: 0.95753 |  0:00:49s\n",
      "epoch 51 | loss: 0.17041 | val_0_auc: 0.95894 |  0:00:50s\n",
      "epoch 52 | loss: 0.16839 | val_0_auc: 0.95384 |  0:00:51s\n",
      "epoch 53 | loss: 0.17311 | val_0_auc: 0.95326 |  0:00:52s\n",
      "epoch 54 | loss: 0.1786  | val_0_auc: 0.95798 |  0:00:53s\n",
      "epoch 55 | loss: 0.16936 | val_0_auc: 0.95912 |  0:00:54s\n",
      "epoch 56 | loss: 0.16671 | val_0_auc: 0.96071 |  0:00:55s\n",
      "epoch 57 | loss: 0.16306 | val_0_auc: 0.95992 |  0:00:56s\n",
      "epoch 58 | loss: 0.16579 | val_0_auc: 0.95667 |  0:00:57s\n",
      "epoch 59 | loss: 0.16972 | val_0_auc: 0.95847 |  0:00:58s\n",
      "epoch 60 | loss: 0.1707  | val_0_auc: 0.95617 |  0:00:59s\n",
      "epoch 61 | loss: 0.17233 | val_0_auc: 0.95898 |  0:01:00s\n",
      "epoch 62 | loss: 0.16283 | val_0_auc: 0.96005 |  0:01:01s\n",
      "epoch 63 | loss: 0.16208 | val_0_auc: 0.96    |  0:01:02s\n",
      "epoch 64 | loss: 0.15857 | val_0_auc: 0.96111 |  0:01:03s\n",
      "epoch 65 | loss: 0.15619 | val_0_auc: 0.95917 |  0:01:04s\n",
      "epoch 66 | loss: 0.15515 | val_0_auc: 0.96062 |  0:01:05s\n",
      "epoch 67 | loss: 0.15355 | val_0_auc: 0.96246 |  0:01:05s\n",
      "epoch 68 | loss: 0.1584  | val_0_auc: 0.96198 |  0:01:06s\n",
      "epoch 69 | loss: 0.15542 | val_0_auc: 0.96106 |  0:01:07s\n",
      "epoch 70 | loss: 0.15366 | val_0_auc: 0.96127 |  0:01:08s\n",
      "epoch 71 | loss: 0.14859 | val_0_auc: 0.96091 |  0:01:09s\n",
      "epoch 72 | loss: 0.15061 | val_0_auc: 0.95883 |  0:01:10s\n",
      "epoch 73 | loss: 0.14993 | val_0_auc: 0.96042 |  0:01:11s\n",
      "epoch 74 | loss: 0.15385 | val_0_auc: 0.95581 |  0:01:12s\n",
      "epoch 75 | loss: 0.15382 | val_0_auc: 0.9584  |  0:01:13s\n",
      "epoch 76 | loss: 0.15879 | val_0_auc: 0.95022 |  0:01:14s\n",
      "epoch 77 | loss: 0.15335 | val_0_auc: 0.95956 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 67 and best_val_0_auc = 0.96246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1837  668]\n",
      " [  20   67]]\n",
      "Accuracy: 0.7345679012345679\n",
      "Precision: 0.09115646258503401\n",
      "Recall: 0.7701149425287356\n",
      "F1-score: 0.16301703163017034\n",
      "{'자기자본구성비율': 0.0018806617480432526, '설비투자효율': 0.0, '총자본투자효율': 0.0, '이자보상배율(이자비용)': 0.0, '유동비율': 6.130755186486271e-06, '당좌비율': 1.2222070310678652e-05, '부채비율': 0.09995807209970252, '총자본정상영업이익률': 2.0646298154725486e-05, '매출액정상영업이익률': 0.0770805197880308, '매출액순이익률': 0.027735767533401793, '자기자본순이익률': 0.2603696032449207, '매출채권회전률': 0.011026483266035189, '재고자산회전률': 0.0, '총자본회전률': 0.001362664690671877, '순운전자본비율': 0.022060860212485003, '매출액증가율': 0.0011563895867826785, '총자본증가율': 0.002105277362745831, '유동자산증가율': 0.0, '유형자산증가율': 0.010082481066257995, '영업이익증가율': 0.0, '순이익증가율': 0.0, 'RETA': 0.06113630268683869, 'EBTA': 0.09446786620546291, 'OM': 0.021231514713407645, '종업원수증가율': 0.02730454231891689, '영업이익변화율': 0.0002694557279012431, '매출액변화율': 0.007696230363738419, '당기순이익변화율': 0.01669296672033391, 'DOL': 0.02131264686452287, 'DFL': 0.0007832475718242894, 'EV/EBITDA': 0.02946811811921706, '영업활동으로 인한 현금흐름': 3.2035403926683165e-05, '금융비용부담률': 0.08893574382562873, '고정비율': 0.00013222447481222736, 'R&D비율': 0.013931186973030835, '채무부담비율': 0.0, '거래량회전율': 0.033782981570454625, '로그시가총액': 0.0005869999625682901, '수정거래량': 0.005612122123664495, '거래량증가율': 0.0013291735332583608, '시가총액증가율': 0.028999427297785332, '시가총액': 0.031437433819976934}\n"
     ]
    }
   ],
   "source": [
    "# Data Resampling case no.1 (with weight to minority)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "train = df[df['회계년도'] <= 2017]\n",
    "test = df[df['회계년도'] > 2017]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority' ,k_neighbors=5)\n",
    "#smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled\n",
    "X_test = X_test\n",
    "y_train = y_resampled\n",
    "y_test = y_test\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# Compute class weights based on the training data\n",
    "class_weights = compute_class_weight('balanced', [0, 1], y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Increase the weight of the minority class\n",
    "class_weights[1] *= 3.5\n",
    "\n",
    "# Define custom loss function with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Train the TabNet classifier with the custom loss function\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], loss_fn=criterion)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# Find the optimal threshold for F1 score\n",
    "#y_pred_proba = clf.predict_proba(X_test)\n",
    "#thresholds = np.linspace(0, 1, 100)\n",
    "#f1_scores = [f1_score(y_test, y_pred_proba[:, 1] > t) for t in thresholds]\n",
    "#optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.6668  | val_0_auc: 0.66477 |  0:00:01s\n",
      "epoch 1  | loss: 0.48715 | val_0_auc: 0.68082 |  0:00:02s\n",
      "epoch 2  | loss: 0.44063 | val_0_auc: 0.79115 |  0:00:03s\n",
      "epoch 3  | loss: 0.42207 | val_0_auc: 0.85135 |  0:00:05s\n",
      "epoch 4  | loss: 0.41402 | val_0_auc: 0.87017 |  0:00:06s\n",
      "epoch 5  | loss: 0.40044 | val_0_auc: 0.87128 |  0:00:07s\n",
      "epoch 6  | loss: 0.39695 | val_0_auc: 0.8889  |  0:00:09s\n",
      "epoch 7  | loss: 0.39604 | val_0_auc: 0.89705 |  0:00:10s\n",
      "epoch 8  | loss: 0.38764 | val_0_auc: 0.89493 |  0:00:11s\n",
      "epoch 9  | loss: 0.38411 | val_0_auc: 0.89852 |  0:00:13s\n",
      "epoch 10 | loss: 0.37878 | val_0_auc: 0.90353 |  0:00:14s\n",
      "epoch 11 | loss: 0.37435 | val_0_auc: 0.90778 |  0:00:15s\n",
      "epoch 12 | loss: 0.364   | val_0_auc: 0.90858 |  0:00:16s\n",
      "epoch 13 | loss: 0.35821 | val_0_auc: 0.90838 |  0:00:18s\n",
      "epoch 14 | loss: 0.35383 | val_0_auc: 0.91143 |  0:00:19s\n",
      "epoch 15 | loss: 0.34963 | val_0_auc: 0.91753 |  0:00:20s\n",
      "epoch 16 | loss: 0.35145 | val_0_auc: 0.92037 |  0:00:22s\n",
      "epoch 17 | loss: 0.34742 | val_0_auc: 0.92053 |  0:00:23s\n",
      "epoch 18 | loss: 0.33947 | val_0_auc: 0.92404 |  0:00:24s\n",
      "epoch 19 | loss: 0.33263 | val_0_auc: 0.92492 |  0:00:25s\n",
      "epoch 20 | loss: 0.32274 | val_0_auc: 0.92821 |  0:00:27s\n",
      "epoch 21 | loss: 0.32785 | val_0_auc: 0.92925 |  0:00:28s\n",
      "epoch 22 | loss: 0.32744 | val_0_auc: 0.92956 |  0:00:29s\n",
      "epoch 23 | loss: 0.3219  | val_0_auc: 0.92818 |  0:00:30s\n",
      "epoch 24 | loss: 0.31727 | val_0_auc: 0.93056 |  0:00:32s\n",
      "epoch 25 | loss: 0.31383 | val_0_auc: 0.93284 |  0:00:33s\n",
      "epoch 26 | loss: 0.30989 | val_0_auc: 0.93604 |  0:00:34s\n",
      "epoch 27 | loss: 0.30672 | val_0_auc: 0.93768 |  0:00:35s\n",
      "epoch 28 | loss: 0.30412 | val_0_auc: 0.93279 |  0:00:37s\n",
      "epoch 29 | loss: 0.29858 | val_0_auc: 0.93862 |  0:00:38s\n",
      "epoch 30 | loss: 0.29084 | val_0_auc: 0.93415 |  0:00:39s\n",
      "epoch 31 | loss: 0.29924 | val_0_auc: 0.93914 |  0:00:40s\n",
      "epoch 32 | loss: 0.29203 | val_0_auc: 0.93734 |  0:00:42s\n",
      "epoch 33 | loss: 0.28914 | val_0_auc: 0.94144 |  0:00:43s\n",
      "epoch 34 | loss: 0.29215 | val_0_auc: 0.94552 |  0:00:44s\n",
      "epoch 35 | loss: 0.30045 | val_0_auc: 0.94529 |  0:00:45s\n",
      "epoch 36 | loss: 0.2996  | val_0_auc: 0.94223 |  0:00:47s\n",
      "epoch 37 | loss: 0.28324 | val_0_auc: 0.94462 |  0:00:48s\n",
      "epoch 38 | loss: 0.27891 | val_0_auc: 0.94591 |  0:00:49s\n",
      "epoch 39 | loss: 0.2818  | val_0_auc: 0.94266 |  0:00:50s\n",
      "epoch 40 | loss: 0.28118 | val_0_auc: 0.94731 |  0:00:52s\n",
      "epoch 41 | loss: 0.27913 | val_0_auc: 0.94707 |  0:00:53s\n",
      "epoch 42 | loss: 0.27332 | val_0_auc: 0.94484 |  0:00:54s\n",
      "epoch 43 | loss: 0.27428 | val_0_auc: 0.94804 |  0:00:56s\n",
      "epoch 44 | loss: 0.27413 | val_0_auc: 0.94925 |  0:00:57s\n",
      "epoch 45 | loss: 0.27659 | val_0_auc: 0.95253 |  0:00:58s\n",
      "epoch 46 | loss: 0.26895 | val_0_auc: 0.94781 |  0:01:00s\n",
      "epoch 47 | loss: 0.27752 | val_0_auc: 0.95408 |  0:01:01s\n",
      "epoch 48 | loss: 0.25791 | val_0_auc: 0.95141 |  0:01:02s\n",
      "epoch 49 | loss: 0.25351 | val_0_auc: 0.95022 |  0:01:04s\n",
      "epoch 50 | loss: 0.26126 | val_0_auc: 0.95677 |  0:01:05s\n",
      "epoch 51 | loss: 0.25457 | val_0_auc: 0.95529 |  0:01:06s\n",
      "epoch 52 | loss: 0.25654 | val_0_auc: 0.95447 |  0:01:08s\n",
      "epoch 53 | loss: 0.24471 | val_0_auc: 0.95627 |  0:01:09s\n",
      "epoch 54 | loss: 0.25159 | val_0_auc: 0.95095 |  0:01:10s\n",
      "epoch 55 | loss: 0.2414  | val_0_auc: 0.95543 |  0:01:11s\n",
      "epoch 56 | loss: 0.24359 | val_0_auc: 0.95415 |  0:01:13s\n",
      "epoch 57 | loss: 0.24563 | val_0_auc: 0.95248 |  0:01:14s\n",
      "epoch 58 | loss: 0.24194 | val_0_auc: 0.95256 |  0:01:15s\n",
      "epoch 59 | loss: 0.24629 | val_0_auc: 0.95968 |  0:01:17s\n",
      "epoch 60 | loss: 0.24453 | val_0_auc: 0.95894 |  0:01:18s\n",
      "epoch 61 | loss: 0.24207 | val_0_auc: 0.9532  |  0:01:19s\n",
      "epoch 62 | loss: 0.23547 | val_0_auc: 0.96031 |  0:01:21s\n",
      "epoch 63 | loss: 0.23881 | val_0_auc: 0.95867 |  0:01:22s\n",
      "epoch 64 | loss: 0.23384 | val_0_auc: 0.95754 |  0:01:23s\n",
      "epoch 65 | loss: 0.22695 | val_0_auc: 0.96089 |  0:01:24s\n",
      "epoch 66 | loss: 0.23396 | val_0_auc: 0.96249 |  0:01:26s\n",
      "epoch 67 | loss: 0.23714 | val_0_auc: 0.96219 |  0:01:27s\n",
      "epoch 68 | loss: 0.23964 | val_0_auc: 0.96239 |  0:01:28s\n",
      "epoch 69 | loss: 0.22824 | val_0_auc: 0.96493 |  0:01:29s\n",
      "epoch 70 | loss: 0.22073 | val_0_auc: 0.96244 |  0:01:31s\n",
      "epoch 71 | loss: 0.22689 | val_0_auc: 0.95822 |  0:01:32s\n",
      "epoch 72 | loss: 0.22728 | val_0_auc: 0.95821 |  0:01:33s\n",
      "epoch 73 | loss: 0.23315 | val_0_auc: 0.9628  |  0:01:34s\n",
      "epoch 74 | loss: 0.22654 | val_0_auc: 0.95215 |  0:01:36s\n",
      "epoch 75 | loss: 0.22821 | val_0_auc: 0.96052 |  0:01:37s\n",
      "epoch 76 | loss: 0.23463 | val_0_auc: 0.96227 |  0:01:38s\n",
      "epoch 77 | loss: 0.21966 | val_0_auc: 0.95847 |  0:01:40s\n",
      "epoch 78 | loss: 0.22277 | val_0_auc: 0.95546 |  0:01:41s\n",
      "epoch 79 | loss: 0.21856 | val_0_auc: 0.96248 |  0:01:42s\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 69 and best_val_0_auc = 0.96493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1597  352]\n",
      " [ 177 1772]]\n",
      "Accuracy: 0.8642893791688046\n",
      "Precision: 0.8342749529190208\n",
      "Recall: 0.9091841970241149\n",
      "F1-score: 0.8701203044438988\n",
      "{'자기자본구성비율': 0.02554252494362828, '설비투자효율': 0.009969267920895052, '총자본투자효율': 0.00015142872846318943, '이자보상배율(이자비용)': 0.0, '유동비율': 0.0, '당좌비율': 0.00011943201185828064, '부채비율': 0.19775674414336428, '총자본정상영업이익률': 0.0869541793689616, '매출액정상영업이익률': 0.0006333398297035835, '매출액순이익률': 0.05180883077035805, '자기자본순이익률': 0.10567379043143872, '매출채권회전률': 0.0, '재고자산회전률': 0.0, '총자본회전률': 0.013643499277014404, '순운전자본비율': 0.0, '매출액증가율': 0.0, '총자본증가율': 2.0025579137308933e-05, '유동자산증가율': 0.0, '유형자산증가율': 6.35931065617222e-06, '영업이익증가율': 0.007944402370875249, '순이익증가율': 2.4567867731420298e-05, 'RETA': 0.11927032295205475, 'EBTA': 0.043717410155811605, 'OM': 1.4770960831933228e-05, '종업원수증가율': 0.01649126832809473, '영업이익변화율': 0.0, '매출액변화율': 0.00016379079438307335, '당기순이익변화율': 0.021083538716762527, 'DOL': 0.005599023726448556, 'DFL': 7.216179656674863e-07, 'EV/EBITDA': 0.0, '영업활동으로 인한 현금흐름': 0.00023274150112770917, '금융비용부담률': 0.06709252490387645, '고정비율': 0.08511152928709856, 'R&D비율': 0.005175981642082952, '채무부담비율': 0.0003632147374340984, '거래량회전율': 0.01216738468600218, '로그시가총액': 0.0066930543525624804, '수정거래량': 0.08754014502801107, '거래량증가율': 0.0, '시가총액증가율': 1.7826249213024337e-05, '시가총액': 0.029016357806153133}\n"
     ]
    }
   ],
   "source": [
    "# Extra for case no.1\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "#sm = BorderlineSMOTE(random_state=42, sampling_strategy='minority')\n",
    "#X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "#X_res_test, y_res_test = sm.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled.values\n",
    "X_test = X_resampled_test.values\n",
    "y_train = y_resampled.values\n",
    "y_test = y_resampled_test.values\n",
    "\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.70121 | val_0_auc: 0.65153 |  0:00:01s\n",
      "epoch 1  | loss: 0.52434 | val_0_auc: 0.717   |  0:00:02s\n",
      "epoch 2  | loss: 0.45251 | val_0_auc: 0.83716 |  0:00:03s\n",
      "epoch 3  | loss: 0.4174  | val_0_auc: 0.84204 |  0:00:04s\n",
      "epoch 4  | loss: 0.40776 | val_0_auc: 0.88255 |  0:00:05s\n",
      "epoch 5  | loss: 0.39427 | val_0_auc: 0.89413 |  0:00:06s\n",
      "epoch 6  | loss: 0.38297 | val_0_auc: 0.89289 |  0:00:08s\n",
      "epoch 7  | loss: 0.37587 | val_0_auc: 0.89555 |  0:00:09s\n",
      "epoch 8  | loss: 0.37906 | val_0_auc: 0.90345 |  0:00:10s\n",
      "epoch 9  | loss: 0.3706  | val_0_auc: 0.90286 |  0:00:11s\n",
      "epoch 10 | loss: 0.37091 | val_0_auc: 0.90259 |  0:00:12s\n",
      "epoch 11 | loss: 0.36953 | val_0_auc: 0.90349 |  0:00:13s\n",
      "epoch 12 | loss: 0.36686 | val_0_auc: 0.90729 |  0:00:14s\n",
      "epoch 13 | loss: 0.36236 | val_0_auc: 0.90763 |  0:00:16s\n",
      "epoch 14 | loss: 0.36125 | val_0_auc: 0.91215 |  0:00:17s\n",
      "epoch 15 | loss: 0.3582  | val_0_auc: 0.91393 |  0:00:18s\n",
      "epoch 16 | loss: 0.35434 | val_0_auc: 0.91306 |  0:00:19s\n",
      "epoch 17 | loss: 0.35241 | val_0_auc: 0.91685 |  0:00:20s\n",
      "epoch 18 | loss: 0.35167 | val_0_auc: 0.91891 |  0:00:22s\n",
      "epoch 19 | loss: 0.35325 | val_0_auc: 0.92014 |  0:00:23s\n",
      "epoch 20 | loss: 0.34967 | val_0_auc: 0.9238  |  0:00:24s\n",
      "epoch 21 | loss: 0.34928 | val_0_auc: 0.92298 |  0:00:25s\n",
      "epoch 22 | loss: 0.34366 | val_0_auc: 0.92648 |  0:00:26s\n",
      "epoch 23 | loss: 0.34219 | val_0_auc: 0.92573 |  0:00:28s\n",
      "epoch 24 | loss: 0.33913 | val_0_auc: 0.92796 |  0:00:29s\n",
      "epoch 25 | loss: 0.33361 | val_0_auc: 0.92927 |  0:00:30s\n",
      "epoch 26 | loss: 0.33161 | val_0_auc: 0.92929 |  0:00:31s\n",
      "epoch 27 | loss: 0.33698 | val_0_auc: 0.93088 |  0:00:32s\n",
      "epoch 28 | loss: 0.33166 | val_0_auc: 0.93203 |  0:00:33s\n",
      "epoch 29 | loss: 0.32582 | val_0_auc: 0.93187 |  0:00:34s\n",
      "epoch 30 | loss: 0.32676 | val_0_auc: 0.92847 |  0:00:36s\n",
      "epoch 31 | loss: 0.32428 | val_0_auc: 0.93129 |  0:00:37s\n",
      "epoch 32 | loss: 0.31996 | val_0_auc: 0.93591 |  0:00:38s\n",
      "epoch 33 | loss: 0.31775 | val_0_auc: 0.93371 |  0:00:39s\n",
      "epoch 34 | loss: 0.31668 | val_0_auc: 0.93735 |  0:00:40s\n",
      "epoch 35 | loss: 0.31873 | val_0_auc: 0.93722 |  0:00:41s\n",
      "epoch 36 | loss: 0.31343 | val_0_auc: 0.93999 |  0:00:42s\n",
      "epoch 37 | loss: 0.31025 | val_0_auc: 0.94113 |  0:00:43s\n",
      "epoch 38 | loss: 0.30872 | val_0_auc: 0.94074 |  0:00:44s\n",
      "epoch 39 | loss: 0.30842 | val_0_auc: 0.94335 |  0:00:46s\n",
      "epoch 40 | loss: 0.2987  | val_0_auc: 0.94473 |  0:00:47s\n",
      "epoch 41 | loss: 0.30324 | val_0_auc: 0.94552 |  0:00:48s\n",
      "epoch 42 | loss: 0.29421 | val_0_auc: 0.94421 |  0:00:49s\n",
      "epoch 43 | loss: 0.29874 | val_0_auc: 0.94472 |  0:00:50s\n",
      "epoch 44 | loss: 0.29417 | val_0_auc: 0.94503 |  0:00:51s\n",
      "epoch 45 | loss: 0.29668 | val_0_auc: 0.94565 |  0:00:52s\n",
      "epoch 46 | loss: 0.2816  | val_0_auc: 0.94917 |  0:00:53s\n",
      "epoch 47 | loss: 0.28529 | val_0_auc: 0.94805 |  0:00:54s\n",
      "epoch 48 | loss: 0.27793 | val_0_auc: 0.94967 |  0:00:56s\n",
      "epoch 49 | loss: 0.28161 | val_0_auc: 0.95071 |  0:00:57s\n",
      "epoch 50 | loss: 0.28597 | val_0_auc: 0.94826 |  0:00:58s\n",
      "epoch 51 | loss: 0.28752 | val_0_auc: 0.95103 |  0:00:59s\n",
      "epoch 52 | loss: 0.28335 | val_0_auc: 0.95098 |  0:01:00s\n",
      "epoch 53 | loss: 0.2823  | val_0_auc: 0.95285 |  0:01:01s\n",
      "epoch 54 | loss: 0.27823 | val_0_auc: 0.95223 |  0:01:02s\n",
      "epoch 55 | loss: 0.2732  | val_0_auc: 0.95265 |  0:01:03s\n",
      "epoch 56 | loss: 0.27168 | val_0_auc: 0.95278 |  0:01:04s\n",
      "epoch 57 | loss: 0.26878 | val_0_auc: 0.95464 |  0:01:06s\n",
      "epoch 58 | loss: 0.26284 | val_0_auc: 0.95717 |  0:01:07s\n",
      "epoch 59 | loss: 0.26665 | val_0_auc: 0.95648 |  0:01:08s\n",
      "epoch 60 | loss: 0.27529 | val_0_auc: 0.95437 |  0:01:09s\n",
      "epoch 61 | loss: 0.26058 | val_0_auc: 0.95692 |  0:01:10s\n",
      "epoch 62 | loss: 0.25421 | val_0_auc: 0.95747 |  0:01:11s\n",
      "epoch 63 | loss: 0.25033 | val_0_auc: 0.95786 |  0:01:13s\n",
      "epoch 64 | loss: 0.25041 | val_0_auc: 0.95716 |  0:01:14s\n",
      "epoch 65 | loss: 0.25026 | val_0_auc: 0.95196 |  0:01:15s\n",
      "epoch 66 | loss: 0.25239 | val_0_auc: 0.95478 |  0:01:16s\n",
      "epoch 67 | loss: 0.24479 | val_0_auc: 0.95815 |  0:01:18s\n",
      "epoch 68 | loss: 0.24504 | val_0_auc: 0.95748 |  0:01:19s\n",
      "epoch 69 | loss: 0.24906 | val_0_auc: 0.95888 |  0:01:20s\n",
      "epoch 70 | loss: 0.24901 | val_0_auc: 0.96209 |  0:01:21s\n",
      "epoch 71 | loss: 0.248   | val_0_auc: 0.95727 |  0:01:22s\n",
      "epoch 72 | loss: 0.24631 | val_0_auc: 0.96374 |  0:01:23s\n",
      "epoch 73 | loss: 0.24285 | val_0_auc: 0.95746 |  0:01:24s\n",
      "epoch 74 | loss: 0.24497 | val_0_auc: 0.95726 |  0:01:26s\n",
      "epoch 75 | loss: 0.24443 | val_0_auc: 0.96307 |  0:01:27s\n",
      "epoch 76 | loss: 0.23805 | val_0_auc: 0.95637 |  0:01:28s\n",
      "epoch 77 | loss: 0.23479 | val_0_auc: 0.96203 |  0:01:29s\n",
      "epoch 78 | loss: 0.2274  | val_0_auc: 0.96015 |  0:01:30s\n",
      "epoch 79 | loss: 0.23609 | val_0_auc: 0.96364 |  0:01:31s\n",
      "epoch 80 | loss: 0.23205 | val_0_auc: 0.96387 |  0:01:32s\n",
      "epoch 81 | loss: 0.2292  | val_0_auc: 0.96477 |  0:01:33s\n",
      "epoch 82 | loss: 0.22741 | val_0_auc: 0.96108 |  0:01:35s\n",
      "epoch 83 | loss: 0.22423 | val_0_auc: 0.96002 |  0:01:36s\n",
      "epoch 84 | loss: 0.22079 | val_0_auc: 0.9582  |  0:01:37s\n",
      "epoch 85 | loss: 0.22427 | val_0_auc: 0.9607  |  0:01:38s\n",
      "epoch 86 | loss: 0.21471 | val_0_auc: 0.96374 |  0:01:39s\n",
      "epoch 87 | loss: 0.21974 | val_0_auc: 0.95775 |  0:01:40s\n",
      "epoch 88 | loss: 0.21935 | val_0_auc: 0.96739 |  0:01:41s\n",
      "epoch 89 | loss: 0.22325 | val_0_auc: 0.95955 |  0:01:42s\n",
      "epoch 90 | loss: 0.21583 | val_0_auc: 0.96702 |  0:01:44s\n",
      "epoch 91 | loss: 0.21624 | val_0_auc: 0.96432 |  0:01:45s\n",
      "epoch 92 | loss: 0.21131 | val_0_auc: 0.96298 |  0:01:46s\n",
      "epoch 93 | loss: 0.20868 | val_0_auc: 0.96561 |  0:01:47s\n",
      "epoch 94 | loss: 0.20854 | val_0_auc: 0.96173 |  0:01:48s\n",
      "epoch 95 | loss: 0.20278 | val_0_auc: 0.96383 |  0:01:49s\n",
      "epoch 96 | loss: 0.19833 | val_0_auc: 0.96616 |  0:01:50s\n",
      "epoch 97 | loss: 0.20255 | val_0_auc: 0.96559 |  0:01:51s\n",
      "epoch 98 | loss: 0.20222 | val_0_auc: 0.96654 |  0:01:53s\n",
      "\n",
      "Early stopping occurred at epoch 98 with best_epoch = 88 and best_val_0_auc = 0.96739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1784  721]\n",
      " [ 288 2217]]\n",
      "Accuracy: 0.7986027944111777\n",
      "Precision: 0.7545949625595644\n",
      "Recall: 0.8850299401197604\n",
      "F1-score: 0.8146242880764284\n",
      "{'자기자본구성비율': 0.015891374992008045, '설비투자효율': 0.0045242446632410335, '총자본투자효율': 0.0, '이자보상배율(이자비용)': 0.05185259401072577, '유동비율': 0.022996984382098042, '당좌비율': 0.016972575501744545, '부채비율': 0.034091570015875976, '총자본정상영업이익률': 0.0, '매출액정상영업이익률': 0.08881435575290814, '매출액순이익률': 0.006690544722667798, '자기자본순이익률': 0.19039009294946668, '매출채권회전률': 7.74683043573838e-06, '재고자산회전률': 0.0, '총자본회전률': 0.00033547288851654735, '순운전자본비율': 0.0006930729652971988, '매출액증가율': 0.012524567760493682, '총자본증가율': 0.0002542533595306181, '유동자산증가율': 0.0, '유형자산증가율': 0.0, '영업이익증가율': 0.0014866190326346318, '순이익증가율': 7.64040343186483e-06, 'RETA': 0.048075953791446295, 'EBTA': 0.16127269610709316, 'OM': 0.07045175382385123, '종업원수증가율': 0.0042413277011958996, '영업이익변화율': 0.021801976057722737, '매출액변화율': 6.611939482877365e-05, '당기순이익변화율': 0.0, 'DOL': 0.0, 'DFL': 0.0009503108883668936, 'EV/EBITDA': 0.0039413797407759354, '영업활동으로 인한 현금흐름': 0.02564916035405224, '금융비용부담률': 0.057867099532558065, '고정비율': 0.00048291392289406327, 'R&D비율': 0.0, '채무부담비율': 0.0, '거래량회전율': 0.0, '로그시가총액': 0.0, '수정거래량': 0.04251240124551997, '거래량증가율': 0.002735341869645074, '시가총액증가율': 0.07615808087531853, '시가총액': 0.036259774463654824}\n"
     ]
    }
   ],
   "source": [
    "# Extra for case no.2\n",
    "\n",
    "train = df[df['회계년도'] <= 2017]\n",
    "test = df[df['회계년도'] > 2017]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "#sm = BorderlineSMOTE(random_state=42, sampling_strategy='minority')\n",
    "#X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "#X_res_test, y_res_test = sm.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled\n",
    "X_test = X_resampled_test\n",
    "y_train = y_resampled\n",
    "y_test = y_resampled_test\n",
    "#X_test = X_test\n",
    "#y_test = y_test\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.69775 | val_0_auc: 0.73531 |  0:00:01s\n",
      "epoch 1  | loss: 0.4982  | val_0_auc: 0.87557 |  0:00:02s\n",
      "epoch 2  | loss: 0.45362 | val_0_auc: 0.85568 |  0:00:03s\n",
      "epoch 3  | loss: 0.43319 | val_0_auc: 0.8973  |  0:00:05s\n",
      "epoch 4  | loss: 0.4229  | val_0_auc: 0.8873  |  0:00:06s\n",
      "epoch 5  | loss: 0.40234 | val_0_auc: 0.89579 |  0:00:07s\n",
      "epoch 6  | loss: 0.3912  | val_0_auc: 0.90327 |  0:00:08s\n",
      "epoch 7  | loss: 0.38062 | val_0_auc: 0.91259 |  0:00:10s\n",
      "epoch 8  | loss: 0.37995 | val_0_auc: 0.91294 |  0:00:11s\n",
      "epoch 9  | loss: 0.37335 | val_0_auc: 0.91595 |  0:00:12s\n",
      "epoch 10 | loss: 0.36993 | val_0_auc: 0.9155  |  0:00:14s\n",
      "epoch 11 | loss: 0.35829 | val_0_auc: 0.91654 |  0:00:15s\n",
      "epoch 12 | loss: 0.35746 | val_0_auc: 0.92822 |  0:00:16s\n",
      "epoch 13 | loss: 0.35346 | val_0_auc: 0.92652 |  0:00:17s\n",
      "epoch 14 | loss: 0.34541 | val_0_auc: 0.92756 |  0:00:19s\n",
      "epoch 15 | loss: 0.3381  | val_0_auc: 0.92104 |  0:00:20s\n",
      "epoch 16 | loss: 0.33688 | val_0_auc: 0.92669 |  0:00:21s\n",
      "epoch 17 | loss: 0.32589 | val_0_auc: 0.93322 |  0:00:22s\n",
      "epoch 18 | loss: 0.31898 | val_0_auc: 0.92506 |  0:00:23s\n",
      "epoch 19 | loss: 0.3201  | val_0_auc: 0.93063 |  0:00:25s\n",
      "epoch 20 | loss: 0.30808 | val_0_auc: 0.92339 |  0:00:26s\n",
      "epoch 21 | loss: 0.31008 | val_0_auc: 0.92809 |  0:00:27s\n",
      "epoch 22 | loss: 0.30431 | val_0_auc: 0.94229 |  0:00:28s\n",
      "epoch 23 | loss: 0.3016  | val_0_auc: 0.94389 |  0:00:30s\n",
      "epoch 24 | loss: 0.30298 | val_0_auc: 0.93826 |  0:00:31s\n",
      "epoch 25 | loss: 0.29495 | val_0_auc: 0.9346  |  0:00:32s\n",
      "epoch 26 | loss: 0.296   | val_0_auc: 0.94336 |  0:00:33s\n",
      "epoch 27 | loss: 0.29715 | val_0_auc: 0.94282 |  0:00:34s\n",
      "epoch 28 | loss: 0.29203 | val_0_auc: 0.94386 |  0:00:35s\n",
      "epoch 29 | loss: 0.29071 | val_0_auc: 0.94791 |  0:00:37s\n",
      "epoch 30 | loss: 0.28797 | val_0_auc: 0.94759 |  0:00:38s\n",
      "epoch 31 | loss: 0.28335 | val_0_auc: 0.93613 |  0:00:39s\n",
      "epoch 32 | loss: 0.28484 | val_0_auc: 0.9473  |  0:00:40s\n",
      "epoch 33 | loss: 0.2802  | val_0_auc: 0.94459 |  0:00:42s\n",
      "epoch 34 | loss: 0.28295 | val_0_auc: 0.94969 |  0:00:43s\n",
      "epoch 35 | loss: 0.27819 | val_0_auc: 0.95245 |  0:00:44s\n",
      "epoch 36 | loss: 0.27369 | val_0_auc: 0.95198 |  0:00:45s\n",
      "epoch 37 | loss: 0.27006 | val_0_auc: 0.95046 |  0:00:47s\n",
      "epoch 38 | loss: 0.26745 | val_0_auc: 0.95565 |  0:00:48s\n",
      "epoch 39 | loss: 0.2649  | val_0_auc: 0.83666 |  0:00:49s\n",
      "epoch 40 | loss: 0.26307 | val_0_auc: 0.95764 |  0:00:50s\n",
      "epoch 41 | loss: 0.26418 | val_0_auc: 0.95735 |  0:00:52s\n",
      "epoch 42 | loss: 0.25756 | val_0_auc: 0.95121 |  0:00:53s\n",
      "epoch 43 | loss: 0.26195 | val_0_auc: 0.95848 |  0:00:54s\n",
      "epoch 44 | loss: 0.26574 | val_0_auc: 0.94485 |  0:00:55s\n",
      "epoch 45 | loss: 0.26586 | val_0_auc: 0.95338 |  0:00:56s\n",
      "epoch 46 | loss: 0.26039 | val_0_auc: 0.95619 |  0:00:58s\n",
      "epoch 47 | loss: 0.2614  | val_0_auc: 0.95918 |  0:00:59s\n",
      "epoch 48 | loss: 0.25707 | val_0_auc: 0.91404 |  0:01:00s\n",
      "epoch 49 | loss: 0.25244 | val_0_auc: 0.95782 |  0:01:01s\n",
      "epoch 50 | loss: 0.24924 | val_0_auc: 0.95429 |  0:01:02s\n",
      "epoch 51 | loss: 0.25164 | val_0_auc: 0.92145 |  0:01:03s\n",
      "epoch 52 | loss: 0.24911 | val_0_auc: 0.95429 |  0:01:05s\n",
      "epoch 53 | loss: 0.24366 | val_0_auc: 0.96035 |  0:01:06s\n",
      "epoch 54 | loss: 0.23882 | val_0_auc: 0.96364 |  0:01:07s\n",
      "epoch 55 | loss: 0.23639 | val_0_auc: 0.96333 |  0:01:08s\n",
      "epoch 56 | loss: 0.24065 | val_0_auc: 0.9608  |  0:01:09s\n",
      "epoch 57 | loss: 0.23754 | val_0_auc: 0.96557 |  0:01:11s\n",
      "epoch 58 | loss: 0.23596 | val_0_auc: 0.9621  |  0:01:12s\n",
      "epoch 59 | loss: 0.23717 | val_0_auc: 0.96329 |  0:01:13s\n",
      "epoch 60 | loss: 0.22752 | val_0_auc: 0.94239 |  0:01:14s\n",
      "epoch 61 | loss: 0.22504 | val_0_auc: 0.85129 |  0:01:15s\n",
      "epoch 62 | loss: 0.22428 | val_0_auc: 0.96408 |  0:01:17s\n",
      "epoch 63 | loss: 0.22793 | val_0_auc: 0.79041 |  0:01:18s\n",
      "epoch 64 | loss: 0.22402 | val_0_auc: 0.96383 |  0:01:19s\n",
      "epoch 65 | loss: 0.22325 | val_0_auc: 0.96256 |  0:01:20s\n",
      "epoch 66 | loss: 0.2291  | val_0_auc: 0.96034 |  0:01:21s\n",
      "epoch 67 | loss: 0.2261  | val_0_auc: 0.82675 |  0:01:23s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_auc = 0.96557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1594  355]\n",
      " [  23   56]]\n",
      "Accuracy: 0.8136094674556213\n",
      "Precision: 0.1362530413625304\n",
      "Recall: 0.7088607594936709\n",
      "F1-score: 0.22857142857142854\n",
      "{'자기자본구성비율': 0.003712294488269945, '설비투자효율': 0.004307703696655136, '총자본투자효율': 0.02433753121364975, '이자보상배율(이자비용)': 0.24027886129880713, '유동비율': 1.7522549303713885e-06, '당좌비율': 0.007554617780065908, '부채비율': 0.0, '총자본정상영업이익률': 0.10925399993491428, '매출액정상영업이익률': 0.0, '매출액순이익률': 0.059757011702196855, '자기자본순이익률': 0.1622812966154025, '매출채권회전률': 0.005381674206391948, '재고자산회전률': 0.0, '총자본회전률': 0.0038837028140515776, '순운전자본비율': 0.010020141063410737, '매출액증가율': 0.0, '총자본증가율': 0.00025299646475380035, '유동자산증가율': 0.0038530444349346355, '유형자산증가율': 0.002649229795278509, '영업이익증가율': 1.369699849541446e-06, '순이익증가율': 0.0, 'RETA': 0.03555725331481567, 'EBTA': 0.048213721297163975, 'OM': 0.05019281904918675, '종업원수증가율': 0.0, '영업이익변화율': 4.334990362899189e-06, '매출액변화율': 0.0, '당기순이익변화율': 0.035300705057068824, 'DOL': 0.0, 'DFL': 0.0010438932081858953, 'EV/EBITDA': 9.02081125771483e-06, '영업활동으로 인한 현금흐름': 0.062069749200628785, '금융비용부담률': 0.05649602072745884, '고정비율': 0.0006393607613525074, 'R&D비율': 0.0, '채무부담비율': 0.021833851353849503, '거래량회전율': 0.007489493534619229, '로그시가총액': 0.0, '수정거래량': 0.0, '거래량증가율': 0.0030286870408078605, '시가총액증가율': 0.00458896346364853, '시가총액': 0.036004898726030354}\n"
     ]
    }
   ],
   "source": [
    "# Data Resampling case no.2 with SMOTE\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled.values\n",
    "X_test = X_test.values\n",
    "y_train = y_resampled.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65257 | val_0_auc: 0.75657 |  0:00:01s\n",
      "epoch 1  | loss: 0.47745 | val_0_auc: 0.79371 |  0:00:02s\n",
      "epoch 2  | loss: 0.4158  | val_0_auc: 0.81363 |  0:00:03s\n",
      "epoch 3  | loss: 0.39094 | val_0_auc: 0.85404 |  0:00:05s\n",
      "epoch 4  | loss: 0.37627 | val_0_auc: 0.8702  |  0:00:06s\n",
      "epoch 5  | loss: 0.3685  | val_0_auc: 0.87425 |  0:00:07s\n",
      "epoch 6  | loss: 0.35904 | val_0_auc: 0.88859 |  0:00:08s\n",
      "epoch 7  | loss: 0.36157 | val_0_auc: 0.89371 |  0:00:09s\n",
      "epoch 8  | loss: 0.3427  | val_0_auc: 0.89865 |  0:00:11s\n",
      "epoch 9  | loss: 0.33641 | val_0_auc: 0.89185 |  0:00:12s\n",
      "epoch 10 | loss: 0.32129 | val_0_auc: 0.89527 |  0:00:13s\n",
      "epoch 11 | loss: 0.31155 | val_0_auc: 0.91829 |  0:00:14s\n",
      "epoch 12 | loss: 0.31312 | val_0_auc: 0.91811 |  0:00:16s\n",
      "epoch 13 | loss: 0.30565 | val_0_auc: 0.91197 |  0:00:17s\n",
      "epoch 14 | loss: 0.3024  | val_0_auc: 0.91245 |  0:00:18s\n",
      "epoch 15 | loss: 0.29261 | val_0_auc: 0.9159  |  0:00:19s\n",
      "epoch 16 | loss: 0.30514 | val_0_auc: 0.92449 |  0:00:20s\n",
      "epoch 17 | loss: 0.29339 | val_0_auc: 0.92431 |  0:00:22s\n",
      "epoch 18 | loss: 0.28184 | val_0_auc: 0.9203  |  0:00:23s\n",
      "epoch 19 | loss: 0.28311 | val_0_auc: 0.92921 |  0:00:24s\n",
      "epoch 20 | loss: 0.2738  | val_0_auc: 0.92864 |  0:00:25s\n",
      "epoch 21 | loss: 0.26951 | val_0_auc: 0.9232  |  0:00:27s\n",
      "epoch 22 | loss: 0.27159 | val_0_auc: 0.92927 |  0:00:28s\n",
      "epoch 23 | loss: 0.2603  | val_0_auc: 0.94028 |  0:00:29s\n",
      "epoch 24 | loss: 0.26634 | val_0_auc: 0.94547 |  0:00:30s\n",
      "epoch 25 | loss: 0.263   | val_0_auc: 0.94648 |  0:00:32s\n",
      "epoch 26 | loss: 0.25948 | val_0_auc: 0.9434  |  0:00:33s\n",
      "epoch 27 | loss: 0.25147 | val_0_auc: 0.94638 |  0:00:34s\n",
      "epoch 28 | loss: 0.25119 | val_0_auc: 0.94962 |  0:00:35s\n",
      "epoch 29 | loss: 0.2479  | val_0_auc: 0.95211 |  0:00:37s\n",
      "epoch 30 | loss: 0.24654 | val_0_auc: 0.95479 |  0:00:38s\n",
      "epoch 31 | loss: 0.23797 | val_0_auc: 0.95717 |  0:00:39s\n",
      "epoch 32 | loss: 0.24318 | val_0_auc: 0.95389 |  0:00:40s\n",
      "epoch 33 | loss: 0.24372 | val_0_auc: 0.95713 |  0:00:42s\n",
      "epoch 34 | loss: 0.23815 | val_0_auc: 0.96114 |  0:00:43s\n",
      "epoch 35 | loss: 0.24008 | val_0_auc: 0.95265 |  0:00:44s\n",
      "epoch 36 | loss: 0.24102 | val_0_auc: 0.93663 |  0:00:45s\n",
      "epoch 37 | loss: 0.23528 | val_0_auc: 0.95698 |  0:00:47s\n",
      "epoch 38 | loss: 0.23712 | val_0_auc: 0.95707 |  0:00:48s\n",
      "epoch 39 | loss: 0.23146 | val_0_auc: 0.95932 |  0:00:49s\n",
      "epoch 40 | loss: 0.22854 | val_0_auc: 0.95218 |  0:00:50s\n",
      "epoch 41 | loss: 0.23807 | val_0_auc: 0.92527 |  0:00:51s\n",
      "epoch 42 | loss: 0.2357  | val_0_auc: 0.94413 |  0:00:53s\n",
      "epoch 43 | loss: 0.23471 | val_0_auc: 0.96165 |  0:00:54s\n",
      "epoch 44 | loss: 0.22858 | val_0_auc: 0.96448 |  0:00:55s\n",
      "epoch 45 | loss: 0.21868 | val_0_auc: 0.9573  |  0:00:56s\n",
      "epoch 46 | loss: 0.21377 | val_0_auc: 0.94764 |  0:00:58s\n",
      "epoch 47 | loss: 0.21281 | val_0_auc: 0.96497 |  0:00:59s\n",
      "epoch 48 | loss: 0.21633 | val_0_auc: 0.96242 |  0:01:00s\n",
      "epoch 49 | loss: 0.21886 | val_0_auc: 0.96395 |  0:01:01s\n",
      "epoch 50 | loss: 0.22075 | val_0_auc: 0.96271 |  0:01:03s\n",
      "epoch 51 | loss: 0.22572 | val_0_auc: 0.96369 |  0:01:04s\n",
      "epoch 52 | loss: 0.22181 | val_0_auc: 0.95647 |  0:01:05s\n",
      "epoch 53 | loss: 0.2156  | val_0_auc: 0.95882 |  0:01:06s\n",
      "epoch 54 | loss: 0.21108 | val_0_auc: 0.89297 |  0:01:08s\n",
      "epoch 55 | loss: 0.21073 | val_0_auc: 0.96331 |  0:01:09s\n",
      "epoch 56 | loss: 0.20387 | val_0_auc: 0.95288 |  0:01:10s\n",
      "epoch 57 | loss: 0.20313 | val_0_auc: 0.96746 |  0:01:11s\n",
      "epoch 58 | loss: 0.2021  | val_0_auc: 0.94694 |  0:01:12s\n",
      "epoch 59 | loss: 0.19575 | val_0_auc: 0.95116 |  0:01:14s\n",
      "epoch 60 | loss: 0.19207 | val_0_auc: 0.97229 |  0:01:15s\n",
      "epoch 61 | loss: 0.18748 | val_0_auc: 0.92027 |  0:01:16s\n",
      "epoch 62 | loss: 0.193   | val_0_auc: 0.95137 |  0:01:17s\n",
      "epoch 63 | loss: 0.19457 | val_0_auc: 0.87428 |  0:01:19s\n",
      "epoch 64 | loss: 0.19694 | val_0_auc: 0.95195 |  0:01:20s\n",
      "epoch 65 | loss: 0.1853  | val_0_auc: 0.90616 |  0:01:21s\n",
      "epoch 66 | loss: 0.19566 | val_0_auc: 0.96439 |  0:01:22s\n",
      "epoch 67 | loss: 0.19476 | val_0_auc: 0.95983 |  0:01:24s\n",
      "epoch 68 | loss: 0.18422 | val_0_auc: 0.97301 |  0:01:25s\n",
      "epoch 69 | loss: 0.1785  | val_0_auc: 0.96557 |  0:01:26s\n",
      "epoch 70 | loss: 0.18092 | val_0_auc: 0.92778 |  0:01:27s\n",
      "epoch 71 | loss: 0.18563 | val_0_auc: 0.89566 |  0:01:29s\n",
      "epoch 72 | loss: 0.18907 | val_0_auc: 0.88208 |  0:01:30s\n",
      "epoch 73 | loss: 0.17255 | val_0_auc: 0.91589 |  0:01:31s\n",
      "epoch 74 | loss: 0.17323 | val_0_auc: 0.95324 |  0:01:32s\n",
      "epoch 75 | loss: 0.18    | val_0_auc: 0.93015 |  0:01:34s\n",
      "epoch 76 | loss: 0.17577 | val_0_auc: 0.85635 |  0:01:35s\n",
      "epoch 77 | loss: 0.17814 | val_0_auc: 0.92292 |  0:01:36s\n",
      "epoch 78 | loss: 0.17409 | val_0_auc: 0.92376 |  0:01:37s\n",
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 68 and best_val_0_auc = 0.97301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1683  266]\n",
      " [  31   48]]\n",
      "Accuracy: 0.8535502958579881\n",
      "Precision: 0.15286624203821655\n",
      "Recall: 0.6075949367088608\n",
      "F1-score: 0.24427480916030533\n",
      "{'자기자본구성비율': 0.0, '설비투자효율': 4.543846886102898e-06, '총자본투자효율': 0.0, '이자보상배율(이자비용)': 0.1517336717152607, '유동비율': 9.634882630671797e-06, '당좌비율': 0.0007334255116842103, '부채비율': 0.045946003184816085, '총자본정상영업이익률': 0.04248568291237684, '매출액정상영업이익률': 0.026456344123703412, '매출액순이익률': 0.008324985911078362, '자기자본순이익률': 0.09088179799059345, '매출채권회전률': 0.0019503855806486071, '재고자산회전률': 0.0009167766462150305, '총자본회전률': 6.036754802568913e-05, '순운전자본비율': 0.005193571658961957, '매출액증가율': 0.0, '총자본증가율': 0.006063050718078008, '유동자산증가율': 0.0, '유형자산증가율': 0.020694832828190967, '영업이익증가율': 0.01696937216859189, '순이익증가율': 4.915787893483473e-05, 'RETA': 0.0, 'EBTA': 0.06026741247603145, 'OM': 0.11899166144538936, '종업원수증가율': 1.3790367978274393e-05, '영업이익변화율': 0.0, '매출액변화율': 0.0, '당기순이익변화율': 4.467763971619613e-06, 'DOL': 0.004660698767887182, 'DFL': 0.0010491714424099088, 'EV/EBITDA': 7.465392782926134e-05, '영업활동으로 인한 현금흐름': 0.0, '금융비용부담률': 0.07197907705731726, '고정비율': 0.0, 'R&D비율': 0.047382924003265305, '채무부담비율': 0.0, '거래량회전율': 0.003440539646926847, '로그시가총액': 0.016434013625341873, '수정거래량': 0.08187540769867921, '거래량증가율': 0.017961255275915442, '시가총액증가율': 0.00012576595946886822, '시가총액': 0.15726555543491125}\n"
     ]
    }
   ],
   "source": [
    "# Data Resampling case no.3 with BorderlineSMOTE\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "sm = BorderlineSMOTE(random_state=42, sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_res.values\n",
    "X_test = X_test.values\n",
    "#y_train = y_resampled.values\n",
    "#y_test = y_resampled_test.values\n",
    "y_train = y_res.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier(mask_type=\"sparsemax\")\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "# Find the optimal threshold for F1 score\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = [f1_score(y_test, y_pred_proba[:, 1] > t) for t in thresholds]\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.40034 | val_0_auc: 0.46156 |  0:00:00s\n",
      "epoch 1  | loss: 0.21533 | val_0_auc: 0.50309 |  0:00:01s\n",
      "epoch 2  | loss: 0.19749 | val_0_auc: 0.62057 |  0:00:02s\n",
      "epoch 3  | loss: 0.17417 | val_0_auc: 0.55469 |  0:00:02s\n",
      "epoch 4  | loss: 0.15966 | val_0_auc: 0.71219 |  0:00:03s\n",
      "epoch 5  | loss: 0.15208 | val_0_auc: 0.763   |  0:00:03s\n",
      "epoch 6  | loss: 0.15089 | val_0_auc: 0.76233 |  0:00:04s\n",
      "epoch 7  | loss: 0.14718 | val_0_auc: 0.79313 |  0:00:05s\n",
      "epoch 8  | loss: 0.14119 | val_0_auc: 0.77597 |  0:00:05s\n",
      "epoch 9  | loss: 0.13731 | val_0_auc: 0.78541 |  0:00:06s\n",
      "epoch 10 | loss: 0.13361 | val_0_auc: 0.78602 |  0:00:07s\n",
      "epoch 11 | loss: 0.12759 | val_0_auc: 0.81955 |  0:00:07s\n",
      "epoch 12 | loss: 0.14331 | val_0_auc: 0.83164 |  0:00:08s\n",
      "epoch 13 | loss: 0.13703 | val_0_auc: 0.8333  |  0:00:08s\n",
      "epoch 14 | loss: 0.13534 | val_0_auc: 0.8299  |  0:00:09s\n",
      "epoch 15 | loss: 0.12712 | val_0_auc: 0.8491  |  0:00:10s\n",
      "epoch 16 | loss: 0.13394 | val_0_auc: 0.8585  |  0:00:10s\n",
      "epoch 17 | loss: 0.13452 | val_0_auc: 0.85635 |  0:00:11s\n",
      "epoch 18 | loss: 0.13332 | val_0_auc: 0.84844 |  0:00:11s\n",
      "epoch 19 | loss: 0.13305 | val_0_auc: 0.84149 |  0:00:12s\n",
      "epoch 20 | loss: 0.12312 | val_0_auc: 0.843   |  0:00:13s\n",
      "epoch 21 | loss: 0.12832 | val_0_auc: 0.84384 |  0:00:13s\n",
      "epoch 22 | loss: 0.13115 | val_0_auc: 0.85162 |  0:00:14s\n",
      "epoch 23 | loss: 0.12909 | val_0_auc: 0.85567 |  0:00:15s\n",
      "epoch 24 | loss: 0.13121 | val_0_auc: 0.8562  |  0:00:15s\n",
      "epoch 25 | loss: 0.12698 | val_0_auc: 0.85098 |  0:00:16s\n",
      "epoch 26 | loss: 0.13192 | val_0_auc: 0.8469  |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.8585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1720  229]\n",
      " [  28   51]]\n",
      "Accuracy: 0.8732741617357002\n",
      "Precision: 0.18214285714285713\n",
      "Recall: 0.6455696202531646\n",
      "F1-score: 0.2841225626740947\n",
      "{'자기자본구성비율': 0.002841075290054547, '설비투자효율': 0.0008899565943526075, '총자본투자효율': 7.012592897536443e-05, '이자보상배율(이자비용)': 0.00032876851497568753, '유동비율': 0.00045656213794516347, '당좌비율': 0.0005359530255079969, '부채비율': 0.012427779512210597, '총자본정상영업이익률': 0.00303521941239578, '매출액정상영업이익률': 0.0008637038078991044, '매출액순이익률': 0.027494607368683487, '자기자본순이익률': 0.28884986771706755, '매출채권회전률': 0.18611284620334587, '재고자산회전률': 0.0009445219893499821, '총자본회전률': 0.005078601912416747, '순운전자본비율': 0.0006180638790743157, '매출액증가율': 0.0, '총자본증가율': 0.10704979422341988, '유동자산증가율': 6.67223745636649e-08, '유형자산증가율': 0.00041207122036000197, '영업이익증가율': 0.0005887820453415095, '순이익증가율': 5.082344811099751e-05, 'RETA': 0.008861586106631725, 'EBTA': 0.15839268488559274, 'OM': 0.0008579370415106809, '종업원수증가율': 0.012374921760111603, '영업이익변화율': 0.0014409445636766225, '매출액변화율': 0.006856792065534876, '당기순이익변화율': 8.978308350122175e-06, 'DOL': 0.00015977259707924935, 'DFL': 0.04172429631628268, 'EV/EBITDA': 0.003054555600617056, '영업활동으로 인한 현금흐름': 0.001826381941726491, '금융비용부담률': 0.04805842330093059, '고정비율': 0.02151993722642299, 'R&D비율': 0.010584649419769927, '채무부담비율': 0.014259120549139791, '거래량회전율': 0.0015741230728611147, '로그시가총액': 0.0003124949956301699, '수정거래량': 0.023464042150563236, '거래량증가율': 0.005817924714932393, '시가총액증가율': 0.0, '시가총액': 0.00020124242877417832}\n"
     ]
    }
   ],
   "source": [
    "# Threshold optimization\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "# Find the optimal threshold for F1 score\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = [f1_score(y_test, y_pred_proba[:, 1] > t) for t in thresholds]\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.40034 | val_0_auc: 0.46156 |  0:00:00s\n",
      "epoch 1  | loss: 0.21533 | val_0_auc: 0.50309 |  0:00:01s\n",
      "epoch 2  | loss: 0.19749 | val_0_auc: 0.62057 |  0:00:01s\n",
      "epoch 3  | loss: 0.17417 | val_0_auc: 0.55469 |  0:00:02s\n",
      "epoch 4  | loss: 0.15966 | val_0_auc: 0.71219 |  0:00:03s\n",
      "epoch 5  | loss: 0.15208 | val_0_auc: 0.763   |  0:00:03s\n",
      "epoch 6  | loss: 0.15089 | val_0_auc: 0.76233 |  0:00:04s\n",
      "epoch 7  | loss: 0.14718 | val_0_auc: 0.79313 |  0:00:05s\n",
      "epoch 8  | loss: 0.14119 | val_0_auc: 0.77597 |  0:00:05s\n",
      "epoch 9  | loss: 0.13731 | val_0_auc: 0.78541 |  0:00:06s\n",
      "epoch 10 | loss: 0.13361 | val_0_auc: 0.78602 |  0:00:06s\n",
      "epoch 11 | loss: 0.12759 | val_0_auc: 0.81955 |  0:00:07s\n",
      "epoch 12 | loss: 0.14331 | val_0_auc: 0.83164 |  0:00:08s\n",
      "epoch 13 | loss: 0.13703 | val_0_auc: 0.8333  |  0:00:08s\n",
      "epoch 14 | loss: 0.13534 | val_0_auc: 0.8299  |  0:00:09s\n",
      "epoch 15 | loss: 0.12712 | val_0_auc: 0.8491  |  0:00:10s\n",
      "epoch 16 | loss: 0.13394 | val_0_auc: 0.8585  |  0:00:10s\n",
      "epoch 17 | loss: 0.13452 | val_0_auc: 0.85635 |  0:00:11s\n",
      "epoch 18 | loss: 0.13332 | val_0_auc: 0.84844 |  0:00:12s\n",
      "epoch 19 | loss: 0.13305 | val_0_auc: 0.84149 |  0:00:12s\n",
      "epoch 20 | loss: 0.12312 | val_0_auc: 0.843   |  0:00:13s\n",
      "epoch 21 | loss: 0.12832 | val_0_auc: 0.84384 |  0:00:13s\n",
      "epoch 22 | loss: 0.13115 | val_0_auc: 0.85162 |  0:00:14s\n",
      "epoch 23 | loss: 0.12909 | val_0_auc: 0.85567 |  0:00:15s\n",
      "epoch 24 | loss: 0.13121 | val_0_auc: 0.8562  |  0:00:15s\n",
      "epoch 25 | loss: 0.12698 | val_0_auc: 0.85098 |  0:00:16s\n",
      "epoch 26 | loss: 0.13192 | val_0_auc: 0.8469  |  0:00:17s\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.8585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[1947    2]\n",
      " [  76    3]]\n",
      "Accuracy: 0.9615384615384616\n",
      "Precision: 0.6\n",
      "Recall: 0.0379746835443038\n",
      "F1-score: 0.07142857142857144\n",
      "{'자기자본구성비율': 0.002841075290054547, '설비투자효율': 0.0008899565943526075, '총자본투자효율': 7.012592897536443e-05, '이자보상배율(이자비용)': 0.00032876851497568753, '유동비율': 0.00045656213794516347, '당좌비율': 0.0005359530255079969, '부채비율': 0.012427779512210597, '총자본정상영업이익률': 0.00303521941239578, '매출액정상영업이익률': 0.0008637038078991044, '매출액순이익률': 0.027494607368683487, '자기자본순이익률': 0.28884986771706755, '매출채권회전률': 0.18611284620334587, '재고자산회전률': 0.0009445219893499821, '총자본회전률': 0.005078601912416747, '순운전자본비율': 0.0006180638790743157, '매출액증가율': 0.0, '총자본증가율': 0.10704979422341988, '유동자산증가율': 6.67223745636649e-08, '유형자산증가율': 0.00041207122036000197, '영업이익증가율': 0.0005887820453415095, '순이익증가율': 5.082344811099751e-05, 'RETA': 0.008861586106631725, 'EBTA': 0.15839268488559274, 'OM': 0.0008579370415106809, '종업원수증가율': 0.012374921760111603, '영업이익변화율': 0.0014409445636766225, '매출액변화율': 0.006856792065534876, '당기순이익변화율': 8.978308350122175e-06, 'DOL': 0.00015977259707924935, 'DFL': 0.04172429631628268, 'EV/EBITDA': 0.003054555600617056, '영업활동으로 인한 현금흐름': 0.001826381941726491, '금융비용부담률': 0.04805842330093059, '고정비율': 0.02151993722642299, 'R&D비율': 0.010584649419769927, '채무부담비율': 0.014259120549139791, '거래량회전율': 0.0015741230728611147, '로그시가총액': 0.0003124949956301699, '수정거래량': 0.023464042150563236, '거래량증가율': 0.005817924714932393, '시가총액증가율': 0.0, '시가총액': 0.00020124242877417832}\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# Select top 10 features based on mutual information\n",
    "selector = SelectKBest(mutual_info_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the selected feature names\n",
    "#selected_feature_indices = selector.get_support(indices=True)\n",
    "#feature_names = np.array(feature_names)\n",
    "#selected_feature_names = feature_names[selected_feature_indices]\n",
    "\n",
    "#print(\"Selected Features:\", selected_feature_names)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1949\n",
       "1      79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_test)\n",
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = X_resampled.values\n",
    "X_test = X_test.values\n",
    "y_train = y_resampled.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_d': [8, 16, 32],\n",
    "    'n_a': [8, 16, 32],\n",
    "    'n_steps': [3, 5, 10],\n",
    "    'gamma': [1.3, 1.4, 1.5],\n",
    "    'n_independent': [1, 2, 4],\n",
    "    'n_shared': [1, 2, 4],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(TabNetClassifier(), param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "best_params = search.best_params_\n",
    "clf = TabNetClassifier(**best_params)\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1)\n",
    "y = df['부실']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train = X_resampled.values\n",
    "X_test = X_test.values\n",
    "y_train = y_resampled.values\n",
    "y_test = y_test.values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest classifier on the resampled data\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the Random Forest as a base estimator in a TabNetClassifier ensemble\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetMultiTaskClassifier\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "    n_d=32, n_a=32,\n",
    "    n_steps=3, gamma=1.3,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params=dict(mode=\"min\", patience=10, min_lr=1e-5, factor=0.5, ),\n",
    "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    mask_type=\"entmax\",\n",
    "    device_name=\"auto\",\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    "    cat_idxs=[],\n",
    "    cat_dims=[],\n",
    ")\n",
    "clf.fit(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    max_epochs=100,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    weights=0.5,  # Weight assigned to the positive class in the loss\n",
    "    from_unsupervised=rf,\n",
    ")\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "epoch 0  | loss: 0.92107 | val_0_auc: 0.45271 |  0:00:00s\n",
      "epoch 1  | loss: 0.38988 | val_0_auc: 0.52385 |  0:00:00s\n",
      "epoch 2  | loss: 0.23659 | val_0_auc: 0.6177  |  0:00:01s\n",
      "epoch 3  | loss: 0.22708 | val_0_auc: 0.58813 |  0:00:01s\n",
      "epoch 4  | loss: 0.21963 | val_0_auc: 0.68821 |  0:00:02s\n",
      "epoch 5  | loss: 0.18548 | val_0_auc: 0.73219 |  0:00:02s\n",
      "epoch 6  | loss: 0.16471 | val_0_auc: 0.69541 |  0:00:03s\n",
      "epoch 7  | loss: 0.17668 | val_0_auc: 0.69511 |  0:00:03s\n",
      "epoch 8  | loss: 0.16385 | val_0_auc: 0.74799 |  0:00:03s\n",
      "epoch 9  | loss: 0.16667 | val_0_auc: 0.76184 |  0:00:04s\n",
      "epoch 10 | loss: 0.15705 | val_0_auc: 0.77656 |  0:00:04s\n",
      "epoch 11 | loss: 0.1598  | val_0_auc: 0.7491  |  0:00:05s\n",
      "epoch 12 | loss: 0.15705 | val_0_auc: 0.68843 |  0:00:05s\n",
      "epoch 13 | loss: 0.15405 | val_0_auc: 0.74547 |  0:00:06s\n",
      "epoch 14 | loss: 0.15123 | val_0_auc: 0.77154 |  0:00:06s\n",
      "epoch 15 | loss: 0.15112 | val_0_auc: 0.85643 |  0:00:06s\n",
      "epoch 16 | loss: 0.14408 | val_0_auc: 0.86795 |  0:00:07s\n",
      "epoch 17 | loss: 0.14568 | val_0_auc: 0.81182 |  0:00:07s\n",
      "epoch 18 | loss: 0.15102 | val_0_auc: 0.83886 |  0:00:08s\n",
      "epoch 19 | loss: 0.13477 | val_0_auc: 0.85491 |  0:00:08s\n",
      "epoch 20 | loss: 0.14606 | val_0_auc: 0.87195 |  0:00:09s\n",
      "epoch 21 | loss: 0.13958 | val_0_auc: 0.89171 |  0:00:09s\n",
      "epoch 22 | loss: 0.13735 | val_0_auc: 0.91303 |  0:00:09s\n",
      "epoch 23 | loss: 0.13959 | val_0_auc: 0.90222 |  0:00:10s\n",
      "epoch 24 | loss: 0.1341  | val_0_auc: 0.89458 |  0:00:10s\n",
      "epoch 25 | loss: 0.13998 | val_0_auc: 0.89539 |  0:00:11s\n",
      "epoch 26 | loss: 0.13908 | val_0_auc: 0.89812 |  0:00:11s\n",
      "epoch 27 | loss: 0.13251 | val_0_auc: 0.90497 |  0:00:12s\n",
      "epoch 28 | loss: 0.14028 | val_0_auc: 0.9072  |  0:00:12s\n",
      "epoch 29 | loss: 0.13493 | val_0_auc: 0.92118 |  0:00:12s\n",
      "epoch 30 | loss: 0.13473 | val_0_auc: 0.92893 |  0:00:13s\n",
      "epoch 31 | loss: 0.13729 | val_0_auc: 0.93502 |  0:00:13s\n",
      "epoch 32 | loss: 0.1405  | val_0_auc: 0.93392 |  0:00:14s\n",
      "epoch 33 | loss: 0.13006 | val_0_auc: 0.93557 |  0:00:14s\n",
      "epoch 34 | loss: 0.13503 | val_0_auc: 0.93843 |  0:00:15s\n",
      "epoch 35 | loss: 0.14236 | val_0_auc: 0.94074 |  0:00:15s\n",
      "epoch 36 | loss: 0.1428  | val_0_auc: 0.92165 |  0:00:15s\n",
      "epoch 37 | loss: 0.13776 | val_0_auc: 0.92433 |  0:00:16s\n",
      "epoch 38 | loss: 0.14014 | val_0_auc: 0.93382 |  0:00:16s\n",
      "epoch 39 | loss: 0.13246 | val_0_auc: 0.93821 |  0:00:17s\n",
      "epoch 40 | loss: 0.13879 | val_0_auc: 0.93836 |  0:00:17s\n",
      "epoch 41 | loss: 0.1257  | val_0_auc: 0.93758 |  0:00:18s\n",
      "epoch 42 | loss: 0.13667 | val_0_auc: 0.93818 |  0:00:18s\n",
      "epoch 43 | loss: 0.1393  | val_0_auc: 0.93696 |  0:00:19s\n",
      "epoch 44 | loss: 0.13391 | val_0_auc: 0.93583 |  0:00:19s\n",
      "epoch 45 | loss: 0.12962 | val_0_auc: 0.93368 |  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.94074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'gamma': 1.3, 'lambda_sparse': 0.0001, 'n_a': 8, 'n_d': 8, 'n_steps': 3}\n",
      "Confusion matrix:\n",
      " [[3660    1]\n",
      " [ 139    1]]\n",
      "Accuracy: 0.9631675874769797\n",
      "Precision: 0.5\n",
      "Recall: 0.007142857142857143\n",
      "F1-score: 0.014084507042253521\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning by GridsearchCV\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 하이퍼파라미터 튜닝\n",
    "hyperparameters = {\n",
    "    \"n_d\": [8, 16, 32],\n",
    "    \"n_a\": [8, 16, 32],\n",
    "    \"n_steps\": [3, 5],\n",
    "    \"gamma\": [1.3, 1.4],\n",
    "    \"lambda_sparse\": [0, 0.0001, 0.001]\n",
    "}\n",
    "\n",
    "# TabNet classifier 생성\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "# GridSearchCV 생성\n",
    "grid_search = GridSearchCV(\n",
    "    clf,\n",
    "    hyperparameters,\n",
    "    cv=5,  # number of cross-validation folds\n",
    "    n_jobs=-1,  # number of CPU cores to use (-1 means all available cores)\n",
    "    scoring=\"recall\",  # metric to optimize\n",
    "    verbose=10  # level of verbosity\n",
    ")\n",
    "\n",
    "# GridSearchCV train data에 적용\n",
    "grid_search.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "# 베스트 하이퍼파라미터\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 베스트 하이퍼파라미터 test data에 적용\n",
    "best_clf = grid_search.best_estimator_\n",
    "preds = best_clf.predict(X_test)\n",
    "\n",
    "# 평가 지표 도출\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.53501 | val_0_auc: 0.52334 |  0:00:00s\n",
      "epoch 1  | loss: 0.31185 | val_0_auc: 0.66771 |  0:00:01s\n",
      "epoch 2  | loss: 0.22119 | val_0_auc: 0.66224 |  0:00:02s\n",
      "epoch 3  | loss: 0.19116 | val_0_auc: 0.56885 |  0:00:03s\n",
      "epoch 4  | loss: 0.20851 | val_0_auc: 0.61162 |  0:00:04s\n",
      "epoch 5  | loss: 0.19698 | val_0_auc: 0.62452 |  0:00:05s\n",
      "epoch 6  | loss: 0.17428 | val_0_auc: 0.67337 |  0:00:05s\n",
      "epoch 7  | loss: 0.2016  | val_0_auc: 0.72645 |  0:00:06s\n",
      "epoch 8  | loss: 0.19585 | val_0_auc: 0.60787 |  0:00:07s\n",
      "epoch 9  | loss: 0.17284 | val_0_auc: 0.75224 |  0:00:08s\n",
      "epoch 10 | loss: 0.15508 | val_0_auc: 0.80195 |  0:00:09s\n",
      "epoch 11 | loss: 0.16229 | val_0_auc: 0.81586 |  0:00:10s\n",
      "epoch 12 | loss: 0.16369 | val_0_auc: 0.84053 |  0:00:10s\n",
      "epoch 13 | loss: 0.14072 | val_0_auc: 0.8628  |  0:00:11s\n",
      "epoch 14 | loss: 0.15576 | val_0_auc: 0.88049 |  0:00:12s\n",
      "epoch 15 | loss: 0.14825 | val_0_auc: 0.8872  |  0:00:13s\n",
      "epoch 16 | loss: 0.15181 | val_0_auc: 0.92165 |  0:00:13s\n",
      "epoch 17 | loss: 0.14218 | val_0_auc: 0.93132 |  0:00:14s\n",
      "epoch 18 | loss: 0.14465 | val_0_auc: 0.93037 |  0:00:15s\n",
      "epoch 19 | loss: 0.14055 | val_0_auc: 0.92946 |  0:00:16s\n",
      "epoch 20 | loss: 0.14187 | val_0_auc: 0.89383 |  0:00:17s\n",
      "epoch 21 | loss: 0.13741 | val_0_auc: 0.89324 |  0:00:17s\n",
      "epoch 22 | loss: 0.14178 | val_0_auc: 0.90062 |  0:00:18s\n",
      "epoch 23 | loss: 0.1304  | val_0_auc: 0.88485 |  0:00:19s\n",
      "epoch 24 | loss: 0.14759 | val_0_auc: 0.88972 |  0:00:20s\n",
      "epoch 25 | loss: 0.13695 | val_0_auc: 0.87253 |  0:00:21s\n",
      "epoch 26 | loss: 0.13538 | val_0_auc: 0.86367 |  0:00:21s\n",
      "epoch 27 | loss: 0.13959 | val_0_auc: 0.8689  |  0:00:22s\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.93132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: OrderedDict([('gamma', 1.1), ('lambda_sparse', 0.0), ('n_a', 32), ('n_d', 32), ('n_steps', 4)])\n",
      "Confusion matrix:\n",
      " [[3643   18]\n",
      " [ 134    6]]\n",
      "Accuracy: 0.9600105235464351\n",
      "Precision: 0.25\n",
      "Recall: 0.04285714285714286\n",
      "F1-score: 0.07317073170731707\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning by BayesSearchCV, case no.1\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "search_space = {\n",
    "    'n_d': [4, 8, 16, 32],\n",
    "    'n_a': [4, 8, 16, 32],\n",
    "    'n_steps': [1, 2, 3, 4],\n",
    "    'gamma': [1.0, 1.1, 1.2, 1.3, 1.4],\n",
    "    'lambda_sparse': [0, 0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    search_space,\n",
    "    cv=5,  \n",
    "    n_iter=50,  \n",
    "    scoring='f1',  \n",
    "    n_jobs=-1, \n",
    "    verbose=10  \n",
    ")\n",
    "\n",
    "# Fit BayesSearchCV to the training data\n",
    "bayes_search.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "# Print best hyperparameters found\n",
    "print(\"Best hyperparameters:\", bayes_search.best_params_)\n",
    "\n",
    "# Use best estimator to make predictions on test data\n",
    "best_clf = bayes_search.best_estimator_\n",
    "preds = best_clf.predict(X_test)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-5aede79f1e02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mrandom_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1633\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[0;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 809\u001b[1;33m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    939\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\Lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning by RandomizedSearchCV\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "\n",
    "param_distributions = {\n",
    "    'n_d': randint(4, 64),\n",
    "    'n_a': randint(4, 64),\n",
    "    'n_steps': randint(1, 5),\n",
    "    'gamma': uniform(1.0, 0.5),\n",
    "    'lambda_sparse': uniform(0.0, 0.01)\n",
    "}\n",
    "\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    clf,\n",
    "    param_distributions,\n",
    "    n_iter=50,  \n",
    "    cv=5,  \n",
    "    scoring='f1',  \n",
    "    n_jobs=-1,  \n",
    "    verbose=10,  \n",
    "    random_state=42  \n",
    ")\n",
    "\n",
    "\n",
    "random_search.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "best_clf = random_search.best_estimator_\n",
    "preds = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.80243 | val_0_auc: 0.47296 |  0:00:00s\n",
      "epoch 1  | loss: 0.50996 | val_0_auc: 0.48818 |  0:00:01s\n",
      "epoch 2  | loss: 0.4785  | val_0_auc: 0.5528  |  0:00:02s\n",
      "epoch 3  | loss: 0.36685 | val_0_auc: 0.67669 |  0:00:03s\n",
      "epoch 4  | loss: 0.27676 | val_0_auc: 0.71056 |  0:00:04s\n",
      "epoch 5  | loss: 0.22776 | val_0_auc: 0.67946 |  0:00:05s\n",
      "epoch 6  | loss: 0.22465 | val_0_auc: 0.74394 |  0:00:06s\n",
      "epoch 7  | loss: 0.22704 | val_0_auc: 0.78297 |  0:00:07s\n",
      "epoch 8  | loss: 0.20818 | val_0_auc: 0.62129 |  0:00:08s\n",
      "epoch 9  | loss: 0.19869 | val_0_auc: 0.67692 |  0:00:09s\n",
      "epoch 10 | loss: 0.20308 | val_0_auc: 0.65017 |  0:00:10s\n",
      "epoch 11 | loss: 0.19193 | val_0_auc: 0.73042 |  0:00:10s\n",
      "epoch 12 | loss: 0.18463 | val_0_auc: 0.78886 |  0:00:11s\n",
      "epoch 13 | loss: 0.17926 | val_0_auc: 0.83275 |  0:00:12s\n",
      "epoch 14 | loss: 0.19301 | val_0_auc: 0.71906 |  0:00:13s\n",
      "epoch 15 | loss: 0.21283 | val_0_auc: 0.56548 |  0:00:14s\n",
      "epoch 16 | loss: 0.19331 | val_0_auc: 0.4635  |  0:00:15s\n",
      "epoch 17 | loss: 0.18182 | val_0_auc: 0.65154 |  0:00:16s\n",
      "epoch 18 | loss: 0.17736 | val_0_auc: 0.63786 |  0:00:17s\n",
      "epoch 19 | loss: 0.1812  | val_0_auc: 0.67208 |  0:00:18s\n",
      "epoch 20 | loss: 0.17998 | val_0_auc: 0.7868  |  0:00:18s\n",
      "epoch 21 | loss: 0.16803 | val_0_auc: 0.70801 |  0:00:19s\n",
      "epoch 22 | loss: 0.18699 | val_0_auc: 0.70141 |  0:00:20s\n",
      "epoch 23 | loss: 0.14825 | val_0_auc: 0.76806 |  0:00:21s\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.83275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: OrderedDict([('gamma', 1.2511469928933538), ('lambda_sparse', 0.0063456874545047785), ('n_a', 4), ('n_d', 50), ('n_steps', 5)])\n",
      "Confusion matrix:\n",
      " [[3649   12]\n",
      " [ 135    5]]\n",
      "Accuracy: 0.9613259668508287\n",
      "Precision: 0.29411764705882354\n",
      "Recall: 0.03571428571428571\n",
      "F1-score: 0.06369426751592357\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning by BayesSearchCV, case no.2\n",
    "\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'n_d': Integer(4, 64),\n",
    "    'n_a': Integer(4, 64),\n",
    "    'n_steps': Integer(1, 5),\n",
    "    'gamma': Real(1.0, 1.5),\n",
    "    'lambda_sparse': Real(0.0, 0.01)\n",
    "}\n",
    "\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    clf,\n",
    "    param_dist,\n",
    "    n_iter=50,  \n",
    "    cv=5,  \n",
    "    scoring='f1',  \n",
    "    n_jobs=-1,  \n",
    "    verbose=10,  \n",
    "    random_state=42,  \n",
    ")\n",
    "\n",
    "\n",
    "bayes_search.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters:\", bayes_search.best_params_)\n",
    "\n",
    "\n",
    "best_clf = bayes_search.best_estimator_\n",
    "preds = best_clf.predict(X_test)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>자기자본순이익률</th>\n",
       "      <td>0.190390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBTA</th>\n",
       "      <td>0.161273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액정상영업이익률</th>\n",
       "      <td>0.088814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시가총액증가율</th>\n",
       "      <td>0.076158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OM</th>\n",
       "      <td>0.070452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금융비용부담률</th>\n",
       "      <td>0.057867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이자보상배율(이자비용)</th>\n",
       "      <td>0.051853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETA</th>\n",
       "      <td>0.048076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수정거래량</th>\n",
       "      <td>0.042512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시가총액</th>\n",
       "      <td>0.036260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부채비율</th>\n",
       "      <td>0.034092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업활동으로 인한 현금흐름</th>\n",
       "      <td>0.025649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유동비율</th>\n",
       "      <td>0.022997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업이익변화율</th>\n",
       "      <td>0.021802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당좌비율</th>\n",
       "      <td>0.016973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자기자본구성비율</th>\n",
       "      <td>0.015891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액증가율</th>\n",
       "      <td>0.012525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액순이익률</th>\n",
       "      <td>0.006691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>설비투자효율</th>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>종업원수증가율</th>\n",
       "      <td>0.004241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV/EBITDA</th>\n",
       "      <td>0.003941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래량증가율</th>\n",
       "      <td>0.002735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업이익증가율</th>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFL</th>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>순운전자본비율</th>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고정비율</th>\n",
       "      <td>0.000483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본회전률</th>\n",
       "      <td>0.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본증가율</th>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액변화율</th>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출채권회전률</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>순이익증가율</th>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOL</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당기순이익변화율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유동자산증가율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본정상영업이익률</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;D비율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>채무부담비율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래량회전율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>로그시가총액</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>재고자산회전률</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본투자효율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유형자산증가율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "자기자본순이익률        0.190390\n",
       "EBTA            0.161273\n",
       "매출액정상영업이익률      0.088814\n",
       "시가총액증가율         0.076158\n",
       "OM              0.070452\n",
       "금융비용부담률         0.057867\n",
       "이자보상배율(이자비용)    0.051853\n",
       "RETA            0.048076\n",
       "수정거래량           0.042512\n",
       "시가총액            0.036260\n",
       "부채비율            0.034092\n",
       "영업활동으로 인한 현금흐름  0.025649\n",
       "유동비율            0.022997\n",
       "영업이익변화율         0.021802\n",
       "당좌비율            0.016973\n",
       "자기자본구성비율        0.015891\n",
       "매출액증가율          0.012525\n",
       "매출액순이익률         0.006691\n",
       "설비투자효율          0.004524\n",
       "종업원수증가율         0.004241\n",
       "EV/EBITDA       0.003941\n",
       "거래량증가율          0.002735\n",
       "영업이익증가율         0.001487\n",
       "DFL             0.000950\n",
       "순운전자본비율         0.000693\n",
       "고정비율            0.000483\n",
       "총자본회전률          0.000335\n",
       "총자본증가율          0.000254\n",
       "매출액변화율          0.000066\n",
       "매출채권회전률         0.000008\n",
       "순이익증가율          0.000008\n",
       "DOL             0.000000\n",
       "당기순이익변화율        0.000000\n",
       "유동자산증가율         0.000000\n",
       "총자본정상영업이익률      0.000000\n",
       "R&D비율           0.000000\n",
       "채무부담비율          0.000000\n",
       "거래량회전율          0.000000\n",
       "로그시가총액          0.000000\n",
       "재고자산회전률         0.000000\n",
       "총자본투자효율         0.000000\n",
       "유형자산증가율         0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_list = {'자기자본구성비율': 0.015891374992008045, '설비투자효율': 0.0045242446632410335, '총자본투자효율': 0.0, '이자보상배율(이자비용)': 0.05185259401072577, \n",
    "                   '유동비율': 0.022996984382098042, '당좌비율': 0.016972575501744545, '부채비율': 0.034091570015875976, '총자본정상영업이익률': 0.0, \n",
    "                   '매출액정상영업이익률': 0.08881435575290814, '매출액순이익률': 0.006690544722667798, '자기자본순이익률': 0.19039009294946668, '매출채권회전률': 7.74683043573838e-06,\n",
    "                   '재고자산회전률': 0.0, '총자본회전률': 0.00033547288851654735, '순운전자본비율': 0.0006930729652971988, '매출액증가율': 0.012524567760493682, \n",
    "                   '총자본증가율': 0.0002542533595306181, '유동자산증가율': 0.0, '유형자산증가율': 0.0, '영업이익증가율': 0.0014866190326346318, \n",
    "                   '순이익증가율': 7.64040343186483e-06, 'RETA': 0.048075953791446295, 'EBTA': 0.16127269610709316, 'OM': 0.07045175382385123, \n",
    "                   '종업원수증가율': 0.0042413277011958996, '영업이익변화율': 0.021801976057722737, '매출액변화율': 6.611939482877365e-05, '당기순이익변화율': 0.0, \n",
    "                   'DOL': 0.0, 'DFL': 0.0009503108883668936, 'EV/EBITDA': 0.0039413797407759354, '영업활동으로 인한 현금흐름': 0.02564916035405224, \n",
    "                   '금융비용부담률': 0.057867099532558065, '고정비율': 0.00048291392289406327, 'R&D비율': 0.0, '채무부담비율': 0.0, \n",
    "                   '거래량회전율': 0.0, '로그시가총액': 0.0, '수정거래량': 0.04251240124551997, '거래량증가율': 0.002735341869645074, \n",
    "                   '시가총액증가율': 0.07615808087531853, '시가총액': 0.036259774463654824}\n",
    "\n",
    "my_series = pd.Series(importance_list)\n",
    "\n",
    "importance = pd.DataFrame(my_series)\n",
    "\n",
    "importance.sort_values(by=0,ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
