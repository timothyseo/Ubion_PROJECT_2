{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Tabnet_Raw_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace((np.inf, -np.inf), np.nan, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.85924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[2171  334]\n",
      " [  33   54]]\n",
      "Accuracy: 0.8584104938271605\n",
      "Precision: 0.13917525773195877\n",
      "Recall: 0.6206896551724138\n",
      "F1-score: 0.22736842105263155\n",
      "{'자기자본구성비율': 0.1328770561183189, '설비투자효율': 0.010130764364031646, '총자본투자효율': 0.03598956454915113, '이자보상배율(이자비용)': 0.050023970314183035, '유동비율': 0.01677674638018684, '당좌비율': 0.024929830033410188, '부채비율': 0.006045296825899569, '총자본정상영업이익률': 0.06008974342432949, '매출액정상영업이익률': 0.03181532866949353, '매출액순이익률': 0.020541046889065762, '자기자본순이익률': 0.041371586534249855, '매출채권회전률': 0.02005254839735838, '재고자산회전률': 0.022990908130517358, '총자본회전률': 0.00790391036018159, '순운전자본비율': 0.018525492996260714, '매출액증가율': 0.013424539667894269, '총자본증가율': 0.02744858606168681, '유동자산증가율': 0.003738112452669213, '유형자산증가율': 0.013073016755354843, '영업이익증가율': 0.010420399434713403, '순이익증가율': 0.012160735546197945, 'RETA': 0.032338742957855514, 'EBTA': 0.05996953713012594, 'OM': 0.018836360758296963, '종업원수증가율': 0.00808998338553831, '영업이익변화율': 0.004377510571429209, '매출액변화율': 0.005028793732433323, '당기순이익변화율': 0.007671648456460962, 'DOL': 0.011568726101696097, 'DFL': 0.004511331648414513, 'EV/EBITDA': 0.03487905150775967, '영업활동으로 인한 현금흐름': 0.01547411649693474, '금융비용부담률': 0.02092365674163546, '고정비율': 0.05855156938610119, 'R&D비율': 0.014345488789073572, '채무부담비율': 0.007946052920553939, '거래량회전율': 0.016562731960152174, '로그시가총액': 0.028930746470718065, '수정거래량': 0.012646252876865303, '거래량증가율': 0.008201692606019162, '시가총액증가율': 0.030802408110701743, '시가총액': 0.01801441348607976}\n"
     ]
    }
   ],
   "source": [
    "# With oversampled data by SMOTE using best hyperparameters set by optuna\n",
    "\n",
    "train = df[df['회계년도'] <= 2017]\n",
    "test = df[df['회계년도'] > 2017]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority' ,k_neighbors=5)\n",
    "#smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled\n",
    "X_test = X_test\n",
    "y_train = y_resampled\n",
    "y_test = y_test\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier(\n",
    "        n_d=46,\n",
    "        n_a=38,\n",
    "        n_steps=5,\n",
    "        gamma=1.5515070542008145,\n",
    "        lambda_sparse=0.5371050923936614,\n",
    "        optimizer_params={\"lr\": 1e-3},\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Train TabNetClassifier on training data\n",
    "clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_name=[\"val\"],\n",
    "        eval_metric=[\"auc\"],\n",
    "        max_epochs=10,\n",
    "        patience=10,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "    )\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 20:48:12,967]\u001b[0m A new study created in memory with name: no-name-477eb293-c7da-4641-949f-bdd2806e9fab\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:48:38,195]\u001b[0m Trial 0 finished with value: 0.7896553447609673 and parameters: {'n_d': 32, 'n_a': 52, 'n_steps': 4, 'gamma': 1.5434205762858304, 'lambda_sparse': 0.10732614367671434}. Best is trial 0 with value: 0.7896553447609673.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:49:06,051]\u001b[0m Trial 1 finished with value: 0.7984267139048176 and parameters: {'n_d': 38, 'n_a': 35, 'n_steps': 5, 'gamma': 1.2543046223356065, 'lambda_sparse': 0.5021987924441852}. Best is trial 1 with value: 0.7984267139048176.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:49:29,498]\u001b[0m Trial 2 finished with value: 0.8294281921795614 and parameters: {'n_d': 40, 'n_a': 16, 'n_steps': 5, 'gamma': 1.4084109527895456, 'lambda_sparse': 0.5798180738918667}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.71806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:49:43,165]\u001b[0m Trial 3 finished with value: 0.7180601825063774 and parameters: {'n_d': 16, 'n_a': 20, 'n_steps': 3, 'gamma': 1.5255644870952074, 'lambda_sparse': 0.03858014537869392}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.73889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:50:19,972]\u001b[0m Trial 4 finished with value: 0.7388855461638867 and parameters: {'n_d': 30, 'n_a': 58, 'n_steps': 6, 'gamma': 1.6302498879535139, 'lambda_sparse': 0.5787208736154049}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.74774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:50:52,023]\u001b[0m Trial 5 finished with value: 0.7477374130384218 and parameters: {'n_d': 32, 'n_a': 37, 'n_steps': 6, 'gamma': 1.224944513185707, 'lambda_sparse': 0.7935917415362422}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.60967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:51:59,557]\u001b[0m Trial 6 finished with value: 0.6096710694520002 and parameters: {'n_d': 55, 'n_a': 50, 'n_steps': 10, 'gamma': 1.6565157740944878, 'lambda_sparse': 0.5225782885482423}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:52:34,966]\u001b[0m Trial 7 finished with value: 0.8269279566936627 and parameters: {'n_d': 59, 'n_a': 24, 'n_steps': 6, 'gamma': 1.2864706751383939, 'lambda_sparse': 0.44036747183390124}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.73941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:53:06,528]\u001b[0m Trial 8 finished with value: 0.7394064986418711 and parameters: {'n_d': 24, 'n_a': 42, 'n_steps': 6, 'gamma': 1.7303120525111568, 'lambda_sparse': 0.5548390144524236}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.64186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:54:05,193]\u001b[0m Trial 9 finished with value: 0.6418629529739466 and parameters: {'n_d': 32, 'n_a': 23, 'n_steps': 10, 'gamma': 1.1780132188508583, 'lambda_sparse': 0.5104663854578342}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:54:58,222]\u001b[0m Trial 10 finished with value: 0.7914685861811108 and parameters: {'n_d': 47, 'n_a': 12, 'n_steps': 8, 'gamma': 1.0515733157800418, 'lambda_sparse': 0.9721427471490856}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.78085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:55:52,636]\u001b[0m Trial 11 finished with value: 0.7808517765248433 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 8, 'gamma': 1.9287114972564263, 'lambda_sparse': 0.2693903736000067}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:56:16,661]\u001b[0m Trial 12 finished with value: 0.768063210182218 and parameters: {'n_d': 47, 'n_a': 24, 'n_steps': 4, 'gamma': 1.3701305871401532, 'lambda_sparse': 0.31729468021789087}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:57:04,278]\u001b[0m Trial 13 finished with value: 0.8041881887962538 and parameters: {'n_d': 64, 'n_a': 30, 'n_steps': 7, 'gamma': 1.3645146440392244, 'lambda_sparse': 0.783957974184309}. Best is trial 2 with value: 0.8294281921795614.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.8326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:57:33,836]\u001b[0m Trial 14 finished with value: 0.8325964386842778 and parameters: {'n_d': 44, 'n_a': 16, 'n_steps': 5, 'gamma': 1.0411061176902978, 'lambda_sparse': 0.34213643644599373}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:57:57,540]\u001b[0m Trial 15 finished with value: 0.7998626973035423 and parameters: {'n_d': 44, 'n_a': 15, 'n_steps': 4, 'gamma': 1.0625302933070995, 'lambda_sparse': 0.283144546278558}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.77758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:58:15,320]\u001b[0m Trial 16 finished with value: 0.7775835686590377 and parameters: {'n_d': 41, 'n_a': 15, 'n_steps': 3, 'gamma': 1.841432611402083, 'lambda_sparse': 0.7109995631309924}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.77622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:58:42,463]\u001b[0m Trial 17 finished with value: 0.776215347529128 and parameters: {'n_d': 52, 'n_a': 8, 'n_steps': 5, 'gamma': 1.0096974333879667, 'lambda_sparse': 0.3915789953170209}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:59:07,430]\u001b[0m Trial 18 finished with value: 0.8095880246289415 and parameters: {'n_d': 23, 'n_a': 31, 'n_steps': 5, 'gamma': 1.3757254514489923, 'lambda_sparse': 0.15109050001841015}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 20:59:51,918]\u001b[0m Trial 19 finished with value: 0.7812071679985236 and parameters: {'n_d': 51, 'n_a': 18, 'n_steps': 8, 'gamma': 1.1427794743316837, 'lambda_sparse': 0.6641416129307685}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.59179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:00:32,800]\u001b[0m Trial 20 finished with value: 0.5917919227375572 and parameters: {'n_d': 39, 'n_a': 28, 'n_steps': 7, 'gamma': 1.453428076125709, 'lambda_sparse': 0.9804817847131488}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:00:56,958]\u001b[0m Trial 21 finished with value: 0.7659250943385346 and parameters: {'n_d': 8, 'n_a': 24, 'n_steps': 5, 'gamma': 1.2698370420672587, 'lambda_sparse': 0.40378259703849784}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:01:41,357]\u001b[0m Trial 22 finished with value: 0.768804510179719 and parameters: {'n_d': 58, 'n_a': 19, 'n_steps': 7, 'gamma': 1.1306870362575825, 'lambda_sparse': 0.3940251560585962}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:02:13,214]\u001b[0m Trial 23 finished with value: 0.7665251027968034 and parameters: {'n_d': 59, 'n_a': 13, 'n_steps': 6, 'gamma': 1.3343005319678776, 'lambda_sparse': 0.20510806590666142}. Best is trial 14 with value: 0.8325964386842778.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.85435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:02:37,011]\u001b[0m Trial 24 finished with value: 0.8543462046401296 and parameters: {'n_d': 47, 'n_a': 27, 'n_steps': 4, 'gamma': 1.4390241699917645, 'lambda_sparse': 0.6204655857183003}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:03:03,286]\u001b[0m Trial 25 finished with value: 0.794401106495374 and parameters: {'n_d': 44, 'n_a': 41, 'n_steps': 4, 'gamma': 1.4803737758392592, 'lambda_sparse': 0.6610796483365095}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:03:23,399]\u001b[0m Trial 26 finished with value: 0.7667238240603151 and parameters: {'n_d': 49, 'n_a': 29, 'n_steps': 3, 'gamma': 1.5882345124201673, 'lambda_sparse': 0.8633846271419341}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.81383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:03:45,198]\u001b[0m Trial 27 finished with value: 0.8138337392661682 and parameters: {'n_d': 42, 'n_a': 17, 'n_steps': 4, 'gamma': 1.4394866773156283, 'lambda_sparse': 0.6394138892844905}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:04:12,669]\u001b[0m Trial 28 finished with value: 0.7784048858037567 and parameters: {'n_d': 36, 'n_a': 34, 'n_steps': 5, 'gamma': 1.713015899340159, 'lambda_sparse': 0.5773416063811971}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:04:28,605]\u001b[0m Trial 29 finished with value: 0.8080717837912654 and parameters: {'n_d': 35, 'n_a': 11, 'n_steps': 3, 'gamma': 1.5746101134533834, 'lambda_sparse': 0.44748226744239306}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.73279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:04:49,681]\u001b[0m Trial 30 finished with value: 0.7327855002201072 and parameters: {'n_d': 26, 'n_a': 21, 'n_steps': 4, 'gamma': 1.8113904341730365, 'lambda_sparse': 0.3301635089307858}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.82181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:05:21,848]\u001b[0m Trial 31 finished with value: 0.8218147888989064 and parameters: {'n_d': 54, 'n_a': 27, 'n_steps': 5, 'gamma': 1.2975857119213554, 'lambda_sparse': 0.4205640928983404}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:05:59,712]\u001b[0m Trial 32 finished with value: 0.8258692313163566 and parameters: {'n_d': 59, 'n_a': 24, 'n_steps': 6, 'gamma': 1.4249229320592722, 'lambda_sparse': 0.4841648054969926}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.83716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:06:27,808]\u001b[0m Trial 33 finished with value: 0.8371639039525106 and parameters: {'n_d': 47, 'n_a': 21, 'n_steps': 5, 'gamma': 1.2102827998344536, 'lambda_sparse': 0.6111549874217564}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.81817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:06:55,732]\u001b[0m Trial 34 finished with value: 0.8181726870959494 and parameters: {'n_d': 46, 'n_a': 16, 'n_steps': 5, 'gamma': 1.1897504914772226, 'lambda_sparse': 0.6099777579396329}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:07:18,368]\u001b[0m Trial 35 finished with value: 0.8065853391285291 and parameters: {'n_d': 39, 'n_a': 20, 'n_steps': 4, 'gamma': 1.1035358591770978, 'lambda_sparse': 0.7627318231880242}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.77536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:07:53,920]\u001b[0m Trial 36 finished with value: 0.7753647147929359 and parameters: {'n_d': 36, 'n_a': 63, 'n_steps': 5, 'gamma': 1.2187117332136177, 'lambda_sparse': 0.05032242666258113}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:08:15,050]\u001b[0m Trial 37 finished with value: 0.798499522300034 and parameters: {'n_d': 50, 'n_a': 33, 'n_steps': 3, 'gamma': 1.0210300112274844, 'lambda_sparse': 0.7061483350086509}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:08:51,539]\u001b[0m Trial 38 finished with value: 0.7895522596073441 and parameters: {'n_d': 42, 'n_a': 39, 'n_steps': 6, 'gamma': 1.4949654496903197, 'lambda_sparse': 0.8499592134222658}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:09:16,397]\u001b[0m Trial 39 finished with value: 0.7887381512146268 and parameters: {'n_d': 29, 'n_a': 46, 'n_steps': 4, 'gamma': 1.0982661198336245, 'lambda_sparse': 0.5395100701513448}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.79597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:09:47,850]\u001b[0m Trial 40 finished with value: 0.7959706920978621 and parameters: {'n_d': 55, 'n_a': 26, 'n_steps': 5, 'gamma': 1.2292073631997809, 'lambda_sparse': 0.6041702232367161}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 7 and best_val_auc = 0.79322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:10:20,850]\u001b[0m Trial 41 finished with value: 0.7932212740844404 and parameters: {'n_d': 45, 'n_a': 22, 'n_steps': 6, 'gamma': 1.3316767813713266, 'lambda_sparse': 0.4806599575919275}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:10:53,515]\u001b[0m Trial 42 finished with value: 0.8038666784569811 and parameters: {'n_d': 49, 'n_a': 13, 'n_steps': 6, 'gamma': 1.2848717489898986, 'lambda_sparse': 0.3565123282427478}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.74116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:11:20,684]\u001b[0m Trial 43 finished with value: 0.7411596671286675 and parameters: {'n_d': 33, 'n_a': 26, 'n_steps': 5, 'gamma': 1.4104691463200958, 'lambda_sparse': 0.4670702323744206}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.70729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:12:02,499]\u001b[0m Trial 44 finished with value: 0.7072852608895408 and parameters: {'n_d': 61, 'n_a': 18, 'n_steps': 7, 'gamma': 1.5252489975310781, 'lambda_sparse': 0.5363555160276059}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.75564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:12:23,040]\u001b[0m Trial 45 finished with value: 0.7556382052322084 and parameters: {'n_d': 39, 'n_a': 10, 'n_steps': 4, 'gamma': 1.1703231019630835, 'lambda_sparse': 0.24178816278708523}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:12:57,144]\u001b[0m Trial 46 finished with value: 0.792502561509878 and parameters: {'n_d': 52, 'n_a': 22, 'n_steps': 6, 'gamma': 1.2548523826417703, 'lambda_sparse': 0.6970208969783914}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.6795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:13:51,740]\u001b[0m Trial 47 finished with value: 0.6795046530091253 and parameters: {'n_d': 54, 'n_a': 32, 'n_steps': 9, 'gamma': 1.3882883208390935, 'lambda_sparse': 0.568914717473985}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n",
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.77444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 21:14:19,524]\u001b[0m Trial 48 finished with value: 0.774435746951659 and parameters: {'n_d': 48, 'n_a': 14, 'n_steps': 5, 'gamma': 1.3199286829048695, 'lambda_sparse': 0.518463161659668}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:14:55,487]\u001b[0m Trial 49 finished with value: 0.7868302348515285 and parameters: {'n_d': 42, 'n_a': 36, 'n_steps': 6, 'gamma': 1.0517636236279744, 'lambda_sparse': 0.3578370686280232}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.81169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:15:19,571]\u001b[0m Trial 50 finished with value: 0.8116872132118161 and parameters: {'n_d': 44, 'n_a': 25, 'n_steps': 4, 'gamma': 1.205189028408926, 'lambda_sparse': 0.7362273549012956}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:16:02,532]\u001b[0m Trial 51 finished with value: 0.6785973114238535 and parameters: {'n_d': 62, 'n_a': 23, 'n_steps': 7, 'gamma': 1.4261566389891347, 'lambda_sparse': 0.49021851730796456}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 7 and best_val_auc = 0.82875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:16:37,169]\u001b[0m Trial 52 finished with value: 0.8287462442402072 and parameters: {'n_d': 57, 'n_a': 19, 'n_steps': 6, 'gamma': 1.458361642584325, 'lambda_sparse': 0.6202433553881859}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.74861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:17:05,965]\u001b[0m Trial 53 finished with value: 0.7486108734892859 and parameters: {'n_d': 52, 'n_a': 19, 'n_steps': 5, 'gamma': 1.3573424137239136, 'lambda_sparse': 0.6503809667589956}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.77433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:17:38,668]\u001b[0m Trial 54 finished with value: 0.7743285768385682 and parameters: {'n_d': 56, 'n_a': 16, 'n_steps': 6, 'gamma': 1.4782687345626602, 'lambda_sparse': 0.6101549873131658}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:18:06,097]\u001b[0m Trial 55 finished with value: 0.8060864934900163 and parameters: {'n_d': 57, 'n_a': 8, 'n_steps': 5, 'gamma': 1.5778653896520203, 'lambda_sparse': 0.4473345609048968}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:18:41,585]\u001b[0m Trial 56 finished with value: 0.5579968127704484 and parameters: {'n_d': 61, 'n_a': 20, 'n_steps': 6, 'gamma': 1.6352492610096925, 'lambda_sparse': 0.6243420291580059}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.74558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:19:20,431]\u001b[0m Trial 57 finished with value: 0.7455843991072681 and parameters: {'n_d': 47, 'n_a': 29, 'n_steps': 7, 'gamma': 1.5268105191303305, 'lambda_sparse': 0.8109229053544209}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.81136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:19:49,636]\u001b[0m Trial 58 finished with value: 0.8113553703280079 and parameters: {'n_d': 64, 'n_a': 12, 'n_steps': 5, 'gamma': 1.2455684936819282, 'lambda_sparse': 0.5651094223335212}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.74536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:20:11,538]\u001b[0m Trial 59 finished with value: 0.7453554010853498 and parameters: {'n_d': 15, 'n_a': 17, 'n_steps': 5, 'gamma': 1.1498541415963823, 'lambda_sparse': 0.15929033850645127}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.76825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:20:33,258]\u001b[0m Trial 60 finished with value: 0.7682544824019947 and parameters: {'n_d': 40, 'n_a': 14, 'n_steps': 4, 'gamma': 1.4561893980141638, 'lambda_sparse': 0.6803190108009874}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:21:10,440]\u001b[0m Trial 61 finished with value: 0.7990642078734951 and parameters: {'n_d': 59, 'n_a': 24, 'n_steps': 6, 'gamma': 1.4027343159023682, 'lambda_sparse': 0.5121286946402807}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.7533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:21:47,442]\u001b[0m Trial 62 finished with value: 0.7532989652076794 and parameters: {'n_d': 58, 'n_a': 21, 'n_steps': 6, 'gamma': 1.3603735347379808, 'lambda_sparse': 0.27064351813379345}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:22:30,119]\u001b[0m Trial 63 finished with value: 0.7664114448069113 and parameters: {'n_d': 53, 'n_a': 28, 'n_steps': 7, 'gamma': 1.4501718496117932, 'lambda_sparse': 0.43885847154364954}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.72726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:23:04,411]\u001b[0m Trial 64 finished with value: 0.7272616738529913 and parameters: {'n_d': 50, 'n_a': 23, 'n_steps': 6, 'gamma': 1.3003097800380001, 'lambda_sparse': 0.30567280439672817}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.74991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:23:35,686]\u001b[0m Trial 65 finished with value: 0.7499118129338467 and parameters: {'n_d': 62, 'n_a': 18, 'n_steps': 5, 'gamma': 1.5348804379099472, 'lambda_sparse': 0.3702620926038659}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:24:32,439]\u001b[0m Trial 66 finished with value: 0.828659979507921 and parameters: {'n_d': 60, 'n_a': 55, 'n_steps': 7, 'gamma': 1.3919242608690547, 'lambda_sparse': 0.5841289677311867}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:25:27,958]\u001b[0m Trial 67 finished with value: 0.7921685560004692 and parameters: {'n_d': 56, 'n_a': 49, 'n_steps': 8, 'gamma': 1.3464603766312873, 'lambda_sparse': 0.7360324739771569}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.75798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:26:14,751]\u001b[0m Trial 68 finished with value: 0.7579829719666051 and parameters: {'n_d': 37, 'n_a': 58, 'n_steps': 7, 'gamma': 1.0963908989991422, 'lambda_sparse': 0.5874858760888505}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 7 and best_val_auc = 0.75717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:26:59,486]\u001b[0m Trial 69 finished with value: 0.7571712664912217 and parameters: {'n_d': 45, 'n_a': 44, 'n_steps': 7, 'gamma': 1.951624389000501, 'lambda_sparse': 0.6567517044953604}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.79293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:28:20,637]\u001b[0m Trial 70 finished with value: 0.7929305210870413 and parameters: {'n_d': 64, 'n_a': 63, 'n_steps': 9, 'gamma': 1.394510088875345, 'lambda_sparse': 0.5549917557244279}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:29:06,385]\u001b[0m Trial 71 finished with value: 0.8011376852408972 and parameters: {'n_d': 59, 'n_a': 52, 'n_steps': 6, 'gamma': 1.4800292225740643, 'lambda_sparse': 0.5003323705305248}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.72916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:29:56,125]\u001b[0m Trial 72 finished with value: 0.729163582922755 and parameters: {'n_d': 61, 'n_a': 25, 'n_steps': 8, 'gamma': 1.4318196833213988, 'lambda_sparse': 0.4127296427250845}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.77325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:30:36,285]\u001b[0m Trial 73 finished with value: 0.7732515892895246 and parameters: {'n_d': 34, 'n_a': 58, 'n_steps': 6, 'gamma': 1.3146479642348012, 'lambda_sparse': 0.625492513056321}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:31:05,944]\u001b[0m Trial 74 finished with value: 0.8270711705667617 and parameters: {'n_d': 43, 'n_a': 30, 'n_steps': 5, 'gamma': 1.502233136221975, 'lambda_sparse': 0.5887978815067608}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:31:31,175]\u001b[0m Trial 75 finished with value: 0.8025549258844178 and parameters: {'n_d': 43, 'n_a': 32, 'n_steps': 4, 'gamma': 1.4910398564439349, 'lambda_sparse': 0.5873667955785563}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:31:50,632]\u001b[0m Trial 76 finished with value: 0.8203098417726994 and parameters: {'n_d': 41, 'n_a': 31, 'n_steps': 3, 'gamma': 1.277191411993252, 'lambda_sparse': 0.6758492327039323}. Best is trial 24 with value: 0.8543462046401296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.85641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:32:22,768]\u001b[0m Trial 77 finished with value: 0.8564057450869953 and parameters: {'n_d': 46, 'n_a': 38, 'n_steps': 5, 'gamma': 1.5515070542008145, 'lambda_sparse': 0.5371050923936614}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.78831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:32:57,757]\u001b[0m Trial 78 finished with value: 0.7883077887201294 and parameters: {'n_d': 46, 'n_a': 55, 'n_steps': 5, 'gamma': 1.5950789213750824, 'lambda_sparse': 0.5364450844448447}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.75899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:33:27,764]\u001b[0m Trial 79 finished with value: 0.758985709370032 and parameters: {'n_d': 30, 'n_a': 47, 'n_steps': 5, 'gamma': 1.6791675667480752, 'lambda_sparse': 0.6009619064756251}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:33:54,380]\u001b[0m Trial 80 finished with value: 0.8076123459970281 and parameters: {'n_d': 48, 'n_a': 40, 'n_steps': 4, 'gamma': 1.5669524866259763, 'lambda_sparse': 0.7374876481260683}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:34:21,187]\u001b[0m Trial 81 finished with value: 0.8080484754931267 and parameters: {'n_d': 38, 'n_a': 27, 'n_steps': 5, 'gamma': 1.516521536797463, 'lambda_sparse': 0.5544492981417463}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.70641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:34:51,270]\u001b[0m Trial 82 finished with value: 0.70641204073041 and parameters: {'n_d': 43, 'n_a': 35, 'n_steps': 5, 'gamma': 1.5502414665322812, 'lambda_sparse': 0.5256631842902564}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.81702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:35:14,130]\u001b[0m Trial 83 finished with value: 0.8170228911516895 and parameters: {'n_d': 51, 'n_a': 16, 'n_steps': 4, 'gamma': 1.4618886317038728, 'lambda_sparse': 0.6289385980967158}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 5 and best_val_auc = 0.80468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:35:44,689]\u001b[0m Trial 84 finished with value: 0.8046817480166321 and parameters: {'n_d': 45, 'n_a': 37, 'n_steps': 5, 'gamma': 1.371984172990748, 'lambda_sparse': 0.6860037362224276}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:36:07,371]\u001b[0m Trial 85 finished with value: 0.7630627392104206 and parameters: {'n_d': 41, 'n_a': 20, 'n_steps': 4, 'gamma': 1.6174768050224746, 'lambda_sparse': 0.4670875042934707}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:36:35,341]\u001b[0m Trial 86 finished with value: 0.8268279953325735 and parameters: {'n_d': 47, 'n_a': 22, 'n_steps': 5, 'gamma': 1.4978022918155216, 'lambda_sparse': 0.5810074347411803}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.78394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:37:09,226]\u001b[0m Trial 87 finished with value: 0.7839352000476739 and parameters: {'n_d': 54, 'n_a': 19, 'n_steps': 6, 'gamma': 1.0231267110013826, 'lambda_sparse': 0.6413413803513944}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.77266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:37:52,954]\u001b[0m Trial 88 finished with value: 0.7726645565848584 and parameters: {'n_d': 49, 'n_a': 61, 'n_steps': 6, 'gamma': 1.4153641403555786, 'lambda_sparse': 0.38258239564205265}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:38:29,860]\u001b[0m Trial 89 finished with value: 0.7665275057141374 and parameters: {'n_d': 43, 'n_a': 26, 'n_steps': 7, 'gamma': 1.0790318791674376, 'lambda_sparse': 0.23465568558779182}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.83409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:38:57,970]\u001b[0m Trial 90 finished with value: 0.8340896115155488 and parameters: {'n_d': 40, 'n_a': 29, 'n_steps': 5, 'gamma': 1.125799160626015, 'lambda_sparse': 0.5520897105047468}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.8121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:39:25,895]\u001b[0m Trial 91 finished with value: 0.8121041193692439 and parameters: {'n_d': 40, 'n_a': 30, 'n_steps': 5, 'gamma': 1.1253651328485257, 'lambda_sparse': 0.5520669675540393}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.76023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:39:53,211]\u001b[0m Trial 92 finished with value: 0.7602284982151131 and parameters: {'n_d': 38, 'n_a': 29, 'n_steps': 5, 'gamma': 1.1847139130850421, 'lambda_sparse': 0.5164069724659568}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:40:18,945]\u001b[0m Trial 93 finished with value: 0.8283831634310583 and parameters: {'n_d': 46, 'n_a': 38, 'n_steps': 4, 'gamma': 1.2282629588913103, 'lambda_sparse': 0.599631913783722}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.83056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:40:44,668]\u001b[0m Trial 94 finished with value: 0.8305645317867516 and parameters: {'n_d': 46, 'n_a': 37, 'n_steps': 4, 'gamma': 1.1453265367591356, 'lambda_sparse': 0.6047132198921253}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.81776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:41:10,620]\u001b[0m Trial 95 finished with value: 0.8177637105657236 and parameters: {'n_d': 46, 'n_a': 38, 'n_steps': 4, 'gamma': 1.1474979871677906, 'lambda_sparse': 0.6157484253231615}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.82985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:41:33,032]\u001b[0m Trial 96 finished with value: 0.8298499041716567 and parameters: {'n_d': 48, 'n_a': 43, 'n_steps': 3, 'gamma': 1.1690613503220726, 'lambda_sparse': 0.7138162423696267}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.83701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:41:54,800]\u001b[0m Trial 97 finished with value: 0.8370053114084749 and parameters: {'n_d': 48, 'n_a': 41, 'n_steps': 3, 'gamma': 1.118844079615918, 'lambda_sparse': 0.7126846937212012}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 8 and best_val_auc = 0.84977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:42:17,356]\u001b[0m Trial 98 finished with value: 0.8497748947041623 and parameters: {'n_d': 50, 'n_a': 44, 'n_steps': 3, 'gamma': 1.0025240918030596, 'lambda_sparse': 0.7965588799012722}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop training because you reached max_epochs = 10 with best_epoch = 9 and best_val_auc = 0.80222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-04-27 21:42:40,810]\u001b[0m Trial 99 finished with value: 0.8022235635840761 and parameters: {'n_d': 48, 'n_a': 43, 'n_steps': 3, 'gamma': 1.005490109532815, 'lambda_sparse': 0.8770051047905871}. Best is trial 77 with value: 0.8564057450869953.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_d': 46, 'n_a': 38, 'n_steps': 5, 'gamma': 1.5515070542008145, 'lambda_sparse': 0.5371050923936614}\n",
      "Best score: 0.8564057450869953\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning with optuna\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "train = df[df['회계년도'] <= 2017]\n",
    "test = df[df['회계년도'] > 2017]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "# Resample using SMOTE\n",
    "smote = SMOTE(sampling_strategy='minority' ,k_neighbors=5)\n",
    "#smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_resampled\n",
    "X_test = X_test\n",
    "y_train = y_resampled\n",
    "y_test = y_test\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to tune\n",
    "    n_d = trial.suggest_int(\"n_d\", 8, 64)\n",
    "    n_a = trial.suggest_int(\"n_a\", 8, 64)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 2.0)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 0.0, 1.0)\n",
    "\n",
    "    # Create TabNetClassifier with specified hyperparameters\n",
    "    model = TabNetClassifier(\n",
    "        n_d=n_d,46\n",
    "        n_a=n_a,38\n",
    "        n_steps=n_steps,5\n",
    "        gamma=gamma,1.5515070542008145\n",
    "        lambda_sparse=lambda_sparse,0.5371050923936614\n",
    "        optimizer_params={\"lr\": 1e-3},\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    # Train TabNetClassifier on training data\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_name=[\"val\"],\n",
    "        eval_metric=[\"auc\"],\n",
    "        max_epochs=10,\n",
    "        patience=10,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "    )\n",
    "\n",
    "    # Return validation AUC score for Optuna to optimize\n",
    "    return model.best_cost\n",
    "\n",
    "# Run Optuna hyperparameter search\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best hyperparameters and validation AUC score\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "print(f\"Best score: {study.best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.64567 | val_0_auc: 0.75382 |  0:00:01s\n",
      "epoch 1  | loss: 0.49475 | val_0_auc: 0.81611 |  0:00:02s\n",
      "epoch 2  | loss: 0.43466 | val_0_auc: 0.86107 |  0:00:03s\n",
      "epoch 3  | loss: 0.40824 | val_0_auc: 0.87643 |  0:00:04s\n",
      "epoch 4  | loss: 0.39722 | val_0_auc: 0.88453 |  0:00:05s\n",
      "epoch 5  | loss: 0.38396 | val_0_auc: 0.90632 |  0:00:06s\n",
      "epoch 6  | loss: 0.37844 | val_0_auc: 0.90867 |  0:00:08s\n",
      "epoch 7  | loss: 0.3671  | val_0_auc: 0.90816 |  0:00:09s\n",
      "epoch 8  | loss: 0.36113 | val_0_auc: 0.90263 |  0:00:10s\n",
      "epoch 9  | loss: 0.35198 | val_0_auc: 0.91918 |  0:00:11s\n",
      "epoch 10 | loss: 0.33541 | val_0_auc: 0.92074 |  0:00:13s\n",
      "epoch 11 | loss: 0.32865 | val_0_auc: 0.92368 |  0:00:14s\n",
      "epoch 12 | loss: 0.32637 | val_0_auc: 0.92447 |  0:00:15s\n",
      "epoch 13 | loss: 0.31584 | val_0_auc: 0.93141 |  0:00:16s\n",
      "epoch 14 | loss: 0.31442 | val_0_auc: 0.93477 |  0:00:17s\n",
      "epoch 15 | loss: 0.30716 | val_0_auc: 0.932   |  0:00:19s\n",
      "epoch 16 | loss: 0.30122 | val_0_auc: 0.93274 |  0:00:20s\n",
      "epoch 17 | loss: 0.29471 | val_0_auc: 0.93437 |  0:00:21s\n",
      "epoch 18 | loss: 0.30275 | val_0_auc: 0.93456 |  0:00:22s\n",
      "epoch 19 | loss: 0.29282 | val_0_auc: 0.93881 |  0:00:23s\n",
      "epoch 20 | loss: 0.28481 | val_0_auc: 0.93427 |  0:00:25s\n",
      "epoch 21 | loss: 0.2782  | val_0_auc: 0.94664 |  0:00:26s\n",
      "epoch 22 | loss: 0.27546 | val_0_auc: 0.94658 |  0:00:27s\n",
      "epoch 23 | loss: 0.28025 | val_0_auc: 0.94762 |  0:00:28s\n",
      "epoch 24 | loss: 0.28326 | val_0_auc: 0.94909 |  0:00:29s\n",
      "epoch 25 | loss: 0.27661 | val_0_auc: 0.9532  |  0:00:31s\n",
      "epoch 26 | loss: 0.27455 | val_0_auc: 0.95614 |  0:00:32s\n",
      "epoch 27 | loss: 0.2649  | val_0_auc: 0.95854 |  0:00:33s\n",
      "epoch 28 | loss: 0.26455 | val_0_auc: 0.96131 |  0:00:34s\n",
      "epoch 29 | loss: 0.25998 | val_0_auc: 0.96093 |  0:00:35s\n",
      "epoch 30 | loss: 0.26178 | val_0_auc: 0.9578  |  0:00:37s\n",
      "epoch 31 | loss: 0.25744 | val_0_auc: 0.96093 |  0:00:38s\n",
      "epoch 32 | loss: 0.2539  | val_0_auc: 0.96336 |  0:00:39s\n",
      "epoch 33 | loss: 0.2452  | val_0_auc: 0.96208 |  0:00:40s\n",
      "epoch 34 | loss: 0.24922 | val_0_auc: 0.96459 |  0:00:42s\n",
      "epoch 35 | loss: 0.24826 | val_0_auc: 0.96642 |  0:00:43s\n",
      "epoch 36 | loss: 0.23918 | val_0_auc: 0.96743 |  0:00:44s\n",
      "epoch 37 | loss: 0.23933 | val_0_auc: 0.96505 |  0:00:45s\n",
      "epoch 38 | loss: 0.23948 | val_0_auc: 0.96057 |  0:00:47s\n",
      "epoch 39 | loss: 0.24289 | val_0_auc: 0.96937 |  0:00:48s\n",
      "epoch 40 | loss: 0.2328  | val_0_auc: 0.96886 |  0:00:50s\n",
      "epoch 41 | loss: 0.23719 | val_0_auc: 0.96654 |  0:00:51s\n",
      "epoch 42 | loss: 0.23562 | val_0_auc: 0.96224 |  0:00:52s\n",
      "epoch 43 | loss: 0.2406  | val_0_auc: 0.9647  |  0:00:53s\n",
      "epoch 44 | loss: 0.22962 | val_0_auc: 0.97054 |  0:00:55s\n",
      "epoch 45 | loss: 0.22113 | val_0_auc: 0.97108 |  0:00:56s\n",
      "epoch 46 | loss: 0.21648 | val_0_auc: 0.97092 |  0:00:57s\n",
      "epoch 47 | loss: 0.21924 | val_0_auc: 0.97167 |  0:00:58s\n",
      "epoch 48 | loss: 0.21241 | val_0_auc: 0.97344 |  0:01:00s\n",
      "epoch 49 | loss: 0.21084 | val_0_auc: 0.97271 |  0:01:01s\n",
      "epoch 50 | loss: 0.20079 | val_0_auc: 0.97521 |  0:01:02s\n",
      "epoch 51 | loss: 0.20337 | val_0_auc: 0.97512 |  0:01:04s\n",
      "epoch 52 | loss: 0.2017  | val_0_auc: 0.97336 |  0:01:05s\n",
      "epoch 53 | loss: 0.20227 | val_0_auc: 0.97525 |  0:01:06s\n",
      "epoch 54 | loss: 0.19271 | val_0_auc: 0.9741  |  0:01:07s\n",
      "epoch 55 | loss: 0.19766 | val_0_auc: 0.9777  |  0:01:08s\n",
      "epoch 56 | loss: 0.1892  | val_0_auc: 0.97618 |  0:01:10s\n",
      "epoch 57 | loss: 0.18904 | val_0_auc: 0.97929 |  0:01:11s\n",
      "epoch 58 | loss: 0.19574 | val_0_auc: 0.97747 |  0:01:12s\n",
      "epoch 59 | loss: 0.18541 | val_0_auc: 0.97504 |  0:01:13s\n",
      "epoch 60 | loss: 0.18383 | val_0_auc: 0.97675 |  0:01:14s\n",
      "epoch 61 | loss: 0.18863 | val_0_auc: 0.97729 |  0:01:16s\n",
      "epoch 62 | loss: 0.19693 | val_0_auc: 0.97208 |  0:01:17s\n",
      "epoch 63 | loss: 0.1933  | val_0_auc: 0.97105 |  0:01:18s\n",
      "epoch 64 | loss: 0.19032 | val_0_auc: 0.97134 |  0:01:19s\n",
      "epoch 65 | loss: 0.18564 | val_0_auc: 0.97155 |  0:01:21s\n",
      "epoch 66 | loss: 0.17784 | val_0_auc: 0.97515 |  0:01:22s\n",
      "epoch 67 | loss: 0.18011 | val_0_auc: 0.9765  |  0:01:23s\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 57 and best_val_0_auc = 0.97929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seopa\\OneDrive\\Documents\\6기\\.venv\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[2185  320]\n",
      " [ 292 2213]]\n",
      "Accuracy: 0.8778443113772455\n",
      "Precision: 0.8736675878405054\n",
      "Recall: 0.883433133732535\n",
      "F1-score: 0.8785232235013894\n",
      "{'자기자본구성비율': 0.0004232720532696617, '설비투자효율': 8.561037829367222e-06, '총자본투자효율': 0.019527258715194947, '이자보상배율(이자비용)': 0.007741363144204045, '유동비율': 0.022316758739469, '당좌비율': 0.007314480000917542, '부채비율': 0.0, '총자본정상영업이익률': 0.00013020730101048503, '매출액정상영업이익률': 0.0, '매출액순이익률': 0.06638812713552099, '자기자본순이익률': 0.24002181042362317, '매출채권회전률': 0.00629503819036634, '재고자산회전률': 0.008553973453161345, '총자본회전률': 0.00015396005335002662, '순운전자본비율': 0.033507139539488105, '매출액증가율': 0.0016823719841356371, '총자본증가율': 0.01372220361576469, '유동자산증가율': 0.0, '유형자산증가율': 0.010147719009483993, '영업이익증가율': 0.007052290710246531, '순이익증가율': 0.0, 'RETA': 0.026332457285370325, 'EBTA': 0.03842151799980565, 'OM': 0.028228369816540585, '종업원수증가율': 1.0625171507134382e-06, '영업이익변화율': 0.0019375806828829214, '매출액변화율': 0.0003217300788560566, '당기순이익변화율': 0.02978431135494589, 'DOL': 0.046627726274766364, 'DFL': 0.015975578380821524, 'EV/EBITDA': 0.02229432701227696, '영업활동으로 인한 현금흐름': 0.00015280255713645582, '금융비용부담률': 0.1156496154107632, '고정비율': 0.0, 'R&D비율': 0.0, '채무부담비율': 1.2086855394997411e-05, '거래량회전율': 0.049089580992175585, '로그시가총액': 0.0, '수정거래량': 0.04490539716986878, '거래량증가율': 0.0, '시가총액증가율': 0.015260593653775049, '시가총액': 0.1200187268504332}\n"
     ]
    }
   ],
   "source": [
    "train = df[df['회계년도'] <= 2017]\n",
    "test = df[df['회계년도'] > 2017]\n",
    "\n",
    "X_train = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "X_test = test.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).values\n",
    "\n",
    "y_train = train['부실'].values\n",
    "y_test = test['부실'].values\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "# Resample using SMOTE\n",
    "#smote = SMOTE()\n",
    "#X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = smote.fit_resample(X_test, y_test)\n",
    "\n",
    "sm = BorderlineSMOTE(random_state=42, sampling_strategy='minority')\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "X_res_test, y_res_test = sm.fit_resample(X_test, y_test)\n",
    "\n",
    "# Resample using Random Under Sampler\n",
    "#rus = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "#X_resampled_test, y_resampled_test = rus.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train = X_res\n",
    "X_test = X_res_test\n",
    "y_train = y_res\n",
    "y_test = y_res_test\n",
    "#X_test = X_test\n",
    "#y_test = y_test\n",
    "\n",
    "feature_names = train.drop(['부실', '회사명', '회계년도', '거래소코드'], axis=1).columns.tolist()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "clf = TabNetClassifier()\n",
    "clf.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "# Feature importance\n",
    "feat_importances = clf.feature_importances_\n",
    "feature_importances_dict = dict(zip(feature_names, feat_importances))\n",
    "\n",
    "# Print the feature importance scores\n",
    "print(feature_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>자기자본순이익률</th>\n",
       "      <td>0.240022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시가총액</th>\n",
       "      <td>0.120019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>금융비용부담률</th>\n",
       "      <td>0.115650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액순이익률</th>\n",
       "      <td>0.066388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래량회전율</th>\n",
       "      <td>0.049090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOL</th>\n",
       "      <td>0.046628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수정거래량</th>\n",
       "      <td>0.044905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EBTA</th>\n",
       "      <td>0.038422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>순운전자본비율</th>\n",
       "      <td>0.033507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당기순이익변화율</th>\n",
       "      <td>0.029784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OM</th>\n",
       "      <td>0.028228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETA</th>\n",
       "      <td>0.026332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유동비율</th>\n",
       "      <td>0.022317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV/EBITDA</th>\n",
       "      <td>0.022294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본투자효율</th>\n",
       "      <td>0.019527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFL</th>\n",
       "      <td>0.015976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시가총액증가율</th>\n",
       "      <td>0.015261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본증가율</th>\n",
       "      <td>0.013722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유형자산증가율</th>\n",
       "      <td>0.010148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>재고자산회전률</th>\n",
       "      <td>0.008554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>이자보상배율(이자비용)</th>\n",
       "      <td>0.007741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>당좌비율</th>\n",
       "      <td>0.007314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업이익증가율</th>\n",
       "      <td>0.007052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출채권회전률</th>\n",
       "      <td>0.006295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업이익변화율</th>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액증가율</th>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자기자본구성비율</th>\n",
       "      <td>0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액변화율</th>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본회전률</th>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>영업활동으로 인한 현금흐름</th>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총자본정상영업이익률</th>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>채무부담비율</th>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>설비투자효율</th>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>종업원수증가율</th>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>매출액정상영업이익률</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>고정비율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R&amp;D비율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>로그시가총액</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>순이익증가율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래량증가율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>유동자산증가율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>부채비율</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "자기자본순이익률        0.240022\n",
       "시가총액            0.120019\n",
       "금융비용부담률         0.115650\n",
       "매출액순이익률         0.066388\n",
       "거래량회전율          0.049090\n",
       "DOL             0.046628\n",
       "수정거래량           0.044905\n",
       "EBTA            0.038422\n",
       "순운전자본비율         0.033507\n",
       "당기순이익변화율        0.029784\n",
       "OM              0.028228\n",
       "RETA            0.026332\n",
       "유동비율            0.022317\n",
       "EV/EBITDA       0.022294\n",
       "총자본투자효율         0.019527\n",
       "DFL             0.015976\n",
       "시가총액증가율         0.015261\n",
       "총자본증가율          0.013722\n",
       "유형자산증가율         0.010148\n",
       "재고자산회전률         0.008554\n",
       "이자보상배율(이자비용)    0.007741\n",
       "당좌비율            0.007314\n",
       "영업이익증가율         0.007052\n",
       "매출채권회전률         0.006295\n",
       "영업이익변화율         0.001938\n",
       "매출액증가율          0.001682\n",
       "자기자본구성비율        0.000423\n",
       "매출액변화율          0.000322\n",
       "총자본회전률          0.000154\n",
       "영업활동으로 인한 현금흐름  0.000153\n",
       "총자본정상영업이익률      0.000130\n",
       "채무부담비율          0.000012\n",
       "설비투자효율          0.000009\n",
       "종업원수증가율         0.000001\n",
       "매출액정상영업이익률      0.000000\n",
       "고정비율            0.000000\n",
       "R&D비율           0.000000\n",
       "로그시가총액          0.000000\n",
       "순이익증가율          0.000000\n",
       "거래량증가율          0.000000\n",
       "유동자산증가율         0.000000\n",
       "부채비율            0.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {'자기자본구성비율': 0.0004232720532696617, '설비투자효율': 8.561037829367222e-06, '총자본투자효율': 0.019527258715194947, \n",
    "            '이자보상배율(이자비용)': 0.007741363144204045, '유동비율': 0.022316758739469, '당좌비율': 0.007314480000917542, \n",
    "            '부채비율': 0.0, '총자본정상영업이익률': 0.00013020730101048503, '매출액정상영업이익률': 0.0, '매출액순이익률': 0.06638812713552099, \n",
    "            '자기자본순이익률': 0.24002181042362317, '매출채권회전률': 0.00629503819036634, '재고자산회전률': 0.008553973453161345, '총자본회전률': 0.00015396005335002662, \n",
    "            '순운전자본비율': 0.033507139539488105, '매출액증가율': 0.0016823719841356371, '총자본증가율': 0.01372220361576469, '유동자산증가율': 0.0, \n",
    "            '유형자산증가율': 0.010147719009483993, '영업이익증가율': 0.007052290710246531, '순이익증가율': 0.0, 'RETA': 0.026332457285370325, \n",
    "            'EBTA': 0.03842151799980565, 'OM': 0.028228369816540585, '종업원수증가율': 1.0625171507134382e-06, '영업이익변화율': 0.0019375806828829214, \n",
    "            '매출액변화율': 0.0003217300788560566, '당기순이익변화율': 0.02978431135494589, 'DOL': 0.046627726274766364, 'DFL': 0.015975578380821524, \n",
    "            'EV/EBITDA': 0.02229432701227696, '영업활동으로 인한 현금흐름': 0.00015280255713645582, '금융비용부담률': 0.1156496154107632, '고정비율': 0.0, \n",
    "            'R&D비율': 0.0, '채무부담비율': 1.2086855394997411e-05, '거래량회전율': 0.049089580992175585, '로그시가총액': 0.0, \n",
    "            '수정거래량': 0.04490539716986878, '거래량증가율': 0.0, '시가총액증가율': 0.015260593653775049, '시가총액': 0.1200187268504332}\n",
    "\n",
    "my_feats = pd.Series(features)\n",
    "\n",
    "feats = pd.DataFrame(my_feats)\n",
    "\n",
    "feats.sort_values(by=0, ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
